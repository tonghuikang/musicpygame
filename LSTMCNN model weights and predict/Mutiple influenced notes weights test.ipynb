{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "height = 108\n",
    "width = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the path to where you save the input numpy arrays\n",
    "lstm = np.array(glob.glob('E:/notes_database/lstm_inputs_2/*'))\n",
    "cnn = np.array(glob.glob('E:/notes_database/cnn_inputs_2/*'))\n",
    "y_train = np.array(glob.glob('E:/notes_database/y_train_2/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function analyzes the actual accuracy\n",
    "def load_test_score(model, cnn_test, lstm_test, y_test):\n",
    "    prediction = model.predict([cnn_test, lstm_test])\n",
    "    error = (prediction - y_test) ** 2\n",
    "    error = (error/y_test.shape[0]).sum()\n",
    "    wrong = 0\n",
    "    for x in range(prediction.shape[0]):\n",
    "        for y in range(prediction.shape[1]):\n",
    "            if abs(prediction[x][y] - y_test[x][y]) > 0.1:\n",
    "                wrong += 1\n",
    "                break\n",
    "    accuracy = 1 - wrong/(prediction.shape[0])\n",
    "    return error, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_model(order, num, start, ending):\n",
    "    cnn_inputs = np.load(cnn[order[num][0]])\n",
    "    labels_inputs = np.load(y_train[order[num][0]])\n",
    "    lstm_inputs = np.load(lstm[order[num][0]])\n",
    "    \n",
    "    count = 0\n",
    "    ce = 0\n",
    "    for file in order[num][start+1:ending]:\n",
    "        if count == ce + 50:\n",
    "            print(count)\n",
    "            ce = count\n",
    "        count+=1\n",
    "        \n",
    "        lstm_inputs = np.append(lstm_inputs, np.load(lstm[file]), axis=0)\n",
    "        cnn_inputs = np.append(cnn_inputs, np.load(cnn[file]), axis=0)\n",
    "        labels_inputs = np.append(labels_inputs, np.load(y_train[file]), axis=0)\n",
    "        \n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(optimizer='adam', loss='mean_squared_error', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(cnn_inputs)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(32)(lstm_layers)\n",
    "    lstm_layers = Dense(32, activation='relu')(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([layers, lstm_layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[cnn_inputs, lstm_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_2(optimizer, loss):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(cnn_inputs)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(32, return_sequences=True)(lstm_layers)\n",
    "    lstm_layers = LSTM(64, return_sequences=True)(lstm_layers)\n",
    "    lstm_layers = LSTM(32)(lstm_layers)\n",
    "    lstm_layers = Dense(32, activation='relu')(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([layers, lstm_layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[cnn_inputs, lstm_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights(y):\n",
    "    samples = []  \n",
    "    for i in range(y.shape[0]):\n",
    "        pos = np.where(y[i] == 1)[0][0]\n",
    "        samples.append(pos)\n",
    "    samples = np.array(samples)\n",
    "    classes = np.unique(samples)\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes, samples)\n",
    "    return classes, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_whole(classifier, num, name, epochs=100, batchsize=32):\n",
    "    lstm_test, cnn_test, labels_test = inputs_to_model(test_order, num, 0, test_order[num].shape[0]+1)\n",
    "    lstm_inputs, cnn_inputs, labels_inputs = inputs_to_model(train_order, num, 0, train_order[num].shape[0]+1)\n",
    "    \n",
    "    sample_weights = class_weight.compute_sample_weight('balanced', labels_inputs)\n",
    "    classifier.fit([cnn_inputs, lstm_inputs], labels_inputs, epochs=epochs, batch_size=batchsize, verbose=1,\n",
    "                  validation_data = ([cnn_test, lstm_test], labels_test), sample_weight=sample_weights)\n",
    "    \n",
    "    #CV_loss, accuracy = load_test_score(classifier, cnn_test, lstm_test, y_test)\n",
    "    #print('val_loss: ', CV_loss)\n",
    "    #print('val_accuarcy', accuracy)\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)   \n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Generate the CV sets\n",
    "kf = KFold(n_splits=3, random_state=7)\n",
    "\n",
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(len(lstm))\n",
    "\n",
    "for x,y in kf.split(length[100:]):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "Train on 35791 samples, validate on 18593 samples\n",
      "Epoch 1/50\n",
      "35791/35791 [==============================] - 40s 1ms/step - loss: 0.1284 - acc: 0.9549 - val_loss: 0.1061 - val_acc: 0.9775\n",
      "Epoch 2/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0600 - acc: 0.9813 - val_loss: 0.0508 - val_acc: 0.9854\n",
      "Epoch 3/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0503 - acc: 0.9845 - val_loss: 0.0705 - val_acc: 0.9774\n",
      "Epoch 4/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0460 - acc: 0.9860 - val_loss: 0.0483 - val_acc: 0.9853\n",
      "Epoch 5/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0429 - acc: 0.9871 - val_loss: 0.0548 - val_acc: 0.9847\n",
      "Epoch 6/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0402 - acc: 0.9879 - val_loss: 0.0347 - val_acc: 0.9901\n",
      "Epoch 7/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0389 - acc: 0.9884 - val_loss: 0.0468 - val_acc: 0.9874\n",
      "Epoch 8/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0369 - acc: 0.9890 - val_loss: 0.0448 - val_acc: 0.9891\n",
      "Epoch 9/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0354 - acc: 0.9895 - val_loss: 0.0405 - val_acc: 0.9894\n",
      "Epoch 10/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0352 - acc: 0.9895 - val_loss: 0.0714 - val_acc: 0.9831\n",
      "Epoch 11/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0342 - acc: 0.9898 - val_loss: 0.0355 - val_acc: 0.9899\n",
      "Epoch 12/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0328 - acc: 0.9902 - val_loss: 0.0573 - val_acc: 0.9860\n",
      "Epoch 13/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0480 - val_acc: 0.9878\n",
      "Epoch 14/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0312 - val_acc: 0.9916\n",
      "Epoch 15/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0306 - acc: 0.9908 - val_loss: 0.1193 - val_acc: 0.9810\n",
      "Epoch 16/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0319 - val_acc: 0.9914\n",
      "Epoch 17/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0292 - acc: 0.9912 - val_loss: 0.0331 - val_acc: 0.9916\n",
      "Epoch 18/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0285 - acc: 0.9914 - val_loss: 0.0418 - val_acc: 0.9899\n",
      "Epoch 19/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0281 - acc: 0.9915 - val_loss: 0.0355 - val_acc: 0.9903\n",
      "Epoch 20/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0280 - acc: 0.9916 - val_loss: 1.2975 - val_acc: 0.8417\n",
      "Epoch 21/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0275 - acc: 0.9918 - val_loss: 0.0644 - val_acc: 0.9873\n",
      "Epoch 22/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0273 - acc: 0.9918 - val_loss: 0.0300 - val_acc: 0.9913\n",
      "Epoch 23/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0274 - acc: 0.9918 - val_loss: 0.0388 - val_acc: 0.9904\n",
      "Epoch 24/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0268 - acc: 0.9920 - val_loss: 0.1202 - val_acc: 0.9801\n",
      "Epoch 25/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0264 - acc: 0.9921 - val_loss: 0.0914 - val_acc: 0.9825\n",
      "Epoch 26/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0261 - acc: 0.9922 - val_loss: 0.0734 - val_acc: 0.9886\n",
      "Epoch 27/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0299 - val_acc: 0.9923\n",
      "Epoch 28/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0254 - acc: 0.9924 - val_loss: 0.1371 - val_acc: 0.9719\n",
      "Epoch 29/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0256 - acc: 0.9923 - val_loss: 0.2503 - val_acc: 0.9448\n",
      "Epoch 30/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0252 - acc: 0.9924 - val_loss: 0.0841 - val_acc: 0.9865\n",
      "Epoch 31/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0383 - val_acc: 0.9908\n",
      "Epoch 32/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.0962 - val_acc: 0.9834\n",
      "Epoch 33/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0249 - acc: 0.9925 - val_loss: 0.2066 - val_acc: 0.9590\n",
      "Epoch 34/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0246 - acc: 0.9926 - val_loss: 0.1729 - val_acc: 0.9691\n",
      "Epoch 35/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0588 - val_acc: 0.9874\n",
      "Epoch 36/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0243 - acc: 0.9927 - val_loss: 0.1011 - val_acc: 0.9887\n",
      "Epoch 37/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0240 - acc: 0.9927 - val_loss: 0.1353 - val_acc: 0.9793\n",
      "Epoch 38/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0235 - acc: 0.9929 - val_loss: 0.1205 - val_acc: 0.9781\n",
      "Epoch 39/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0242 - acc: 0.9928 - val_loss: 0.1275 - val_acc: 0.9752\n",
      "Epoch 40/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0238 - acc: 0.9928 - val_loss: 0.1100 - val_acc: 0.9836\n",
      "Epoch 41/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0236 - acc: 0.9930 - val_loss: 0.7676 - val_acc: 0.9181\n",
      "Epoch 42/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.0289 - val_acc: 0.9922\n",
      "Epoch 43/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.1548 - val_acc: 0.9587\n",
      "Epoch 44/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0235 - acc: 0.9930 - val_loss: 0.0284 - val_acc: 0.9928\n",
      "Epoch 45/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0228 - acc: 0.9931 - val_loss: 0.0315 - val_acc: 0.9921\n",
      "Epoch 46/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0928 - val_acc: 0.9856\n",
      "Epoch 47/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0222 - acc: 0.9933 - val_loss: 0.0287 - val_acc: 0.9927\n",
      "Epoch 48/50\n",
      "35791/35791 [==============================] - 37s 1ms/step - loss: 0.0229 - acc: 0.9931 - val_loss: 0.0349 - val_acc: 0.9919\n",
      "Epoch 49/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0228 - acc: 0.9932 - val_loss: 0.0585 - val_acc: 0.9864\n",
      "Epoch 50/50\n",
      "35791/35791 [==============================] - 38s 1ms/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.0332 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32524"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "classifier = main(optimizer=adam, loss='binary_crossentropy')\n",
    "train_test_whole(classifier, 0, 'weight-spectrums2-temp-lr0.01.hdf5', epochs=50)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(num, name, epochs=100, batchsize=32, optimizer='adam', loss='mean_squared_error',\n",
    "                     metrix='accuracy', split=2):\n",
    "    classifier = main(optimizer, loss, metrix)\n",
    "    \n",
    "    lstm_test, cnn_test, labels_test = inputs_to_model(test_order, num, 0, test_order[num].shape[0]+1)\n",
    "    for epoch in range(epochs):\n",
    "        print(\"\"\"\n",
    "        \n",
    "        THIS IS EPOCH {}\"\"\".format(epoch))\n",
    "        for i in range(split):\n",
    "            lstm,cnn,labels = inputs_to_model(train_order, num, (train_order[num].shape[0]*i)//split, \n",
    "                                              (train_order[num].shape[0]*(i+1))//split+1)\n",
    "            sample_weights = class_weight.compute_sample_weight('balanced', labels)\n",
    "            classifier.fit([cnn, lstm], labels, epochs=1, batch_size=batchsize, verbose=1,\n",
    "                  validation_data = ([cnn_test, lstm_test], labels_test), sample_weight=sample_weights)\n",
    "            \n",
    "            # To save memory, it's possible to train the model first then test on the validation data.\n",
    "            #CV_loss, accuracy = load_test_score(classifier, cnn_test, lstm_test, labels_test)\n",
    "            #print('val_loss: ', CV_loss)\n",
    "            #print('val_accuarcy', accuracy)\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)\n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the CV sets\n",
    "kf = KFold(n_splits=3, random_state=7)\n",
    "\n",
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(len(lstm))\n",
    "\n",
    "for x,y in kf.split(length):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 46s 1ms/step - loss: 0.1278 - acc: 0.9552 - val_loss: 0.0896 - val_acc: 0.9734\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0632 - acc: 0.9801 - val_loss: 0.1186 - val_acc: 0.9678\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0529 - acc: 0.9838 - val_loss: 0.0576 - val_acc: 0.9822\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0480 - acc: 0.9855 - val_loss: 0.0372 - val_acc: 0.9889\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0450 - acc: 0.9866 - val_loss: 0.0399 - val_acc: 0.9883\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0420 - acc: 0.9876 - val_loss: 0.0430 - val_acc: 0.9878\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0394 - acc: 0.9884 - val_loss: 0.0460 - val_acc: 0.9867\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 44s 1ms/step - loss: 0.0384 - acc: 0.9888 - val_loss: 0.0390 - val_acc: 0.9882\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0363 - acc: 0.9893 - val_loss: 0.0415 - val_acc: 0.9882\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0356 - acc: 0.9895 - val_loss: 0.0303 - val_acc: 0.9915\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0343 - acc: 0.9900 - val_loss: 0.0421 - val_acc: 0.9875\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0337 - acc: 0.9900 - val_loss: 0.0330 - val_acc: 0.9903\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0325 - acc: 0.9905 - val_loss: 0.0450 - val_acc: 0.9893\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0323 - acc: 0.9905 - val_loss: 0.1594 - val_acc: 0.9662\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0316 - acc: 0.9907 - val_loss: 0.0415 - val_acc: 0.9904\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0309 - acc: 0.9909 - val_loss: 0.0305 - val_acc: 0.9915\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 44s 1ms/step - loss: 0.0315 - acc: 0.9908 - val_loss: 0.0324 - val_acc: 0.9910\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 44s 1ms/step - loss: 0.0303 - acc: 0.9912 - val_loss: 0.0314 - val_acc: 0.9906\n",
      "50\n",
      "Train on 36274 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36274/36274 [==============================] - 43s 1ms/step - loss: 0.0299 - acc: 0.9912 - val_loss: 0.0278 - val_acc: 0.9923\n",
      "50\n",
      "Train on 36319 samples, validate on 36454 samples\n",
      "Epoch 1/1\n",
      "36319/36319 [==============================] - 43s 1ms/step - loss: 0.0293 - acc: 0.9914 - val_loss: 0.1014 - val_acc: 0.9882\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "classifier = main(optimizer=adam, loss='binary_crossentropy')\n",
    "train_test_split(classifier, 0, 'weight-split-test.hdf5', epochs=10)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "100\n",
      "50\n",
      "Train on 72054 samples, validate on 36454 samples\n",
      "Epoch 1/30\n",
      "72054/72054 [==============================] - 77s 1ms/step - loss: 0.0953 - acc: 0.9676 - val_loss: 0.0518 - val_acc: 0.9847\n",
      "Epoch 2/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0493 - acc: 0.9849 - val_loss: 0.0631 - val_acc: 0.9825\n",
      "Epoch 3/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0427 - acc: 0.9872 - val_loss: 0.1129 - val_acc: 0.9727\n",
      "Epoch 4/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0387 - acc: 0.9885 - val_loss: 0.0406 - val_acc: 0.9872\n",
      "Epoch 5/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0360 - acc: 0.9893 - val_loss: 0.0618 - val_acc: 0.9876\n",
      "Epoch 6/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0339 - acc: 0.9901 - val_loss: 0.0323 - val_acc: 0.9912\n",
      "Epoch 7/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0324 - acc: 0.9905 - val_loss: 0.0277 - val_acc: 0.9922\n",
      "Epoch 8/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0318 - acc: 0.9906 - val_loss: 0.0336 - val_acc: 0.9904\n",
      "Epoch 9/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0946 - val_acc: 0.9810\n",
      "Epoch 10/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0299 - acc: 0.9913 - val_loss: 0.0386 - val_acc: 0.9902\n",
      "Epoch 11/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0294 - acc: 0.9914 - val_loss: 0.0313 - val_acc: 0.9916\n",
      "Epoch 12/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0283 - acc: 0.9917 - val_loss: 0.1298 - val_acc: 0.9855\n",
      "Epoch 13/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0283 - acc: 0.9918 - val_loss: 0.0870 - val_acc: 0.9891\n",
      "Epoch 14/30\n",
      "72054/72054 [==============================] - 76s 1ms/step - loss: 0.0277 - acc: 0.9919 - val_loss: 0.0336 - val_acc: 0.9924\n",
      "Epoch 15/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0271 - acc: 0.9921 - val_loss: 0.0322 - val_acc: 0.9919\n",
      "Epoch 16/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0270 - acc: 0.9921 - val_loss: 0.0437 - val_acc: 0.9890\n",
      "Epoch 17/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0266 - acc: 0.9923 - val_loss: 0.0564 - val_acc: 0.9910\n",
      "Epoch 18/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0264 - acc: 0.9924 - val_loss: 0.0363 - val_acc: 0.9922\n",
      "Epoch 19/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0263 - acc: 0.9924 - val_loss: 0.0397 - val_acc: 0.9916\n",
      "Epoch 20/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0258 - acc: 0.9925 - val_loss: 0.0281 - val_acc: 0.9926\n",
      "Epoch 21/30\n",
      "72054/72054 [==============================] - 76s 1ms/step - loss: 0.0255 - acc: 0.9926 - val_loss: 0.0256 - val_acc: 0.9929\n",
      "Epoch 22/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0255 - acc: 0.9926 - val_loss: 0.0789 - val_acc: 0.9870\n",
      "Epoch 23/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0251 - acc: 0.9927 - val_loss: 0.0254 - val_acc: 0.9930\n",
      "Epoch 24/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0250 - acc: 0.9927 - val_loss: 0.3492 - val_acc: 0.9478\n",
      "Epoch 25/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0248 - val_acc: 0.9933\n",
      "Epoch 26/30\n",
      "72054/72054 [==============================] - 74s 1ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.2923 - val_acc: 0.9393\n",
      "Epoch 27/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0275 - val_acc: 0.9927\n",
      "Epoch 28/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0245 - acc: 0.9929 - val_loss: 0.0268 - val_acc: 0.9927\n",
      "Epoch 29/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0244 - acc: 0.9930 - val_loss: 0.4865 - val_acc: 0.9283\n",
      "Epoch 30/30\n",
      "72054/72054 [==============================] - 75s 1ms/step - loss: 0.0241 - acc: 0.9930 - val_loss: 0.0496 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "52726"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "classifier = main(optimizer=adam, loss='binary_crossentropy')\n",
    "train_test_whole(classifier, 0, 'weight-spectrums2-all-lr0.01.hdf5', epochs=30)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  import sys\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "100\n",
      "Train on 72054 samples, validate on 36454 samples\n",
      "Epoch 1/30\n",
      "72054/72054 [==============================] - 120s 2ms/step - loss: 0.0976 - acc: 0.9665 - val_loss: 0.0847 - val_acc: 0.9715\n",
      "Epoch 2/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0510 - acc: 0.9844 - val_loss: 0.1273 - val_acc: 0.9759\n",
      "Epoch 3/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0431 - acc: 0.9871 - val_loss: 0.1006 - val_acc: 0.9826\n",
      "Epoch 4/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0384 - acc: 0.9886 - val_loss: 0.0864 - val_acc: 0.9866\n",
      "Epoch 5/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0353 - acc: 0.9896 - val_loss: 0.1546 - val_acc: 0.9788\n",
      "Epoch 6/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0332 - acc: 0.9903 - val_loss: 0.1435 - val_acc: 0.9763\n",
      "Epoch 7/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0315 - acc: 0.9908 - val_loss: 0.0298 - val_acc: 0.9915\n",
      "Epoch 8/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0299 - acc: 0.9913 - val_loss: 0.0327 - val_acc: 0.9910\n",
      "Epoch 9/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0285 - acc: 0.9917 - val_loss: 2.1518 - val_acc: 0.8468\n",
      "Epoch 10/30\n",
      "72054/72054 [==============================] - 117s 2ms/step - loss: 0.0283 - acc: 0.9918 - val_loss: 0.1409 - val_acc: 0.9833\n",
      "Epoch 11/30\n",
      "72054/72054 [==============================] - 118s 2ms/step - loss: 0.0271 - acc: 0.9921 - val_loss: 0.0295 - val_acc: 0.9920\n",
      "Epoch 12/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0266 - acc: 0.9924 - val_loss: 0.0596 - val_acc: 0.9880\n",
      "Epoch 13/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0259 - acc: 0.9925 - val_loss: 0.0320 - val_acc: 0.9914\n",
      "Epoch 14/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0257 - acc: 0.9926 - val_loss: 0.0290 - val_acc: 0.9918\n",
      "Epoch 15/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0249 - acc: 0.9928 - val_loss: 0.0963 - val_acc: 0.9889\n",
      "Epoch 16/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0246 - acc: 0.9928 - val_loss: 0.0704 - val_acc: 0.9873\n",
      "Epoch 17/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0242 - acc: 0.9930 - val_loss: 0.1258 - val_acc: 0.9856\n",
      "Epoch 18/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0243 - acc: 0.9930 - val_loss: 0.1028 - val_acc: 0.9906\n",
      "Epoch 19/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0240 - acc: 0.9931 - val_loss: 0.0435 - val_acc: 0.9907\n",
      "Epoch 20/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0236 - acc: 0.9932 - val_loss: 0.0352 - val_acc: 0.9905\n",
      "Epoch 21/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0232 - acc: 0.9933 - val_loss: 0.5861 - val_acc: 0.9315\n",
      "Epoch 22/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0283 - val_acc: 0.9922\n",
      "Epoch 23/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0229 - acc: 0.9934 - val_loss: 0.0364 - val_acc: 0.9917\n",
      "Epoch 24/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0227 - acc: 0.9934 - val_loss: 0.0368 - val_acc: 0.9901\n",
      "Epoch 25/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0225 - acc: 0.9935 - val_loss: 0.0591 - val_acc: 0.9910\n",
      "Epoch 26/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0226 - acc: 0.9935 - val_loss: 0.3798 - val_acc: 0.8898\n",
      "Epoch 27/30\n",
      "72054/72054 [==============================] - 114s 2ms/step - loss: 0.0220 - acc: 0.9937 - val_loss: 0.0347 - val_acc: 0.9912\n",
      "Epoch 28/30\n",
      "72054/72054 [==============================] - 115s 2ms/step - loss: 0.0222 - acc: 0.9936 - val_loss: 0.1093 - val_acc: 0.9870\n",
      "Epoch 29/30\n",
      "72054/72054 [==============================] - 116s 2ms/step - loss: 0.0220 - acc: 0.9937 - val_loss: 0.0350 - val_acc: 0.9915\n",
      "Epoch 30/30\n",
      "72054/72054 [==============================] - 120s 2ms/step - loss: 0.0217 - acc: 0.9938 - val_loss: 0.1482 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64158"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.01)\n",
    "classifier = main_2(optimizer=adam, loss='binary_crossentropy')\n",
    "train_test_whole(classifier, 0, 'weight-spectrums2-main_2-lr0.01.hdf5', epochs=30)\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
