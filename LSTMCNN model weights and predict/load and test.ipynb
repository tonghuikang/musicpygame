{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = 5\n",
    "height = 108\n",
    "width = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(optimizer, loss):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(cnn_inputs)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(64, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(32)(lstm_layers)\n",
    "    lstm_layers = Dense(32, activation='relu')(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([layers, lstm_layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[cnn_inputs, lstm_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_score(model, cnn_test, lstm_test, y_test):\n",
    "    prediction = model.predict([cnn_test, lstm_test])\n",
    "    wrong = 0\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if abs(prediction[i][j] - y_test[i][j]) > 0.5:\n",
    "                wrong += 1\n",
    "                break\n",
    "    print(prediction.shape[0])\n",
    "    print(wrong)\n",
    "    accuracy = 1 - wrong/(prediction.shape[0])\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if sys.path[0] == '':\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "classifier = main(optimizer='adam', loss='binary_crossentropy')\n",
    "classifier.load_weights('weight-spectrums2-all-lr0.01.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change the path to where you save the input numpy arrays\n",
    "lstm = np.array(glob.glob('E:/notes_database/lstm_inputs_2/*'))\n",
    "cnn = np.array(glob.glob('E:/notes_database/cnn_inputs_2/*'))\n",
    "y_train = np.array(glob.glob('E:/notes_database/y_train_2/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate the CV sets\n",
    "kf = KFold(n_splits=3, random_state=7)\n",
    "\n",
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(len(lstm))\n",
    "\n",
    "for x,y in kf.split(length):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_arrays(test_order, num=0):\n",
    "    cnn_test = np.load(cnn[test_order[num][0]])\n",
    "    labels_test = np.load(y_train[test_order[num][0]])\n",
    "    lstm_test = np.load(lstm[test_order[num][0]])\n",
    "    \n",
    "    count = 0\n",
    "    ce = 0\n",
    "    for i in test_order[num][1:]:\n",
    "        if count == ce + 50:\n",
    "            print(count)\n",
    "            ce = count\n",
    "        count+=1\n",
    "        \n",
    "        lstm_test = np.append(lstm_test, np.load(lstm[i]), axis=0)\n",
    "        cnn_test = np.append(cnn_test, np.load(cnn[i]), axis=0)\n",
    "        labels_test = np.append(labels_test, np.load(y_train[i]), axis=0)\n",
    "    \n",
    "    return cnn_test, lstm_test, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "a,b,c = generate_test_arrays(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = load_test_score(classifier, a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wanna see the output in the standard format\n",
    "def return_prediction(prediction):\n",
    "    output = 'The notes are: C4'\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if prediction[i][j] < 0.5:\n",
    "                prediction[i][j] = 0\n",
    "            elif prediction[i][j] > 0.5:\n",
    "                prediction[i][j] = 1\n",
    "                output+='_{}'.format(j+60)\n",
    "        print(output)\n",
    "    return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
