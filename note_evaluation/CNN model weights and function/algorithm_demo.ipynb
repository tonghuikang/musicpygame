{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is written one month before the first working game prototype\n",
    "# code needs to be updated\n",
    "# this is largely for demostration and to appreciate why picking peaks in the first octave don't usually work\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import pyaudio\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the size of each individual block of audio, we call this \"chunk\"\n",
    "chunksize = 2048\n",
    "\n",
    "# todo: variable frequency for CQT\n",
    "\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-input\", required=False, type=int, help=\"Audio Input Device\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # this is here so you can choose the default audio input\n",
    "# if args.input is None:\n",
    "#     print(\"No input device specified. Printing list of input devices now: \")\n",
    "#     p = pyaudio.PyAudio()\n",
    "#     for i in range(p.get_device_count()):\n",
    "#         print(\"Device number (%i): %s\" % (i, p.get_device_info_by_index(i).get('name')))\n",
    "#         print(\"Run this program with -input 1, or the number of the input you'd like to use.\")\n",
    "#         exit()\n",
    "\n",
    "# starting audio channel?\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=pyaudio.paFloat32,\n",
    "channels=1, rate=44100, input=True,\n",
    "input_device_index=0, frames_per_buffer=chunksize)\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_onset(signal, chunksize=2048, tempo_res=32, plotting = False):\n",
    "    '''\n",
    "    # this is to be called at the end of every chunk (2048 entries), starting from 4th chunk\n",
    "    # the input to this function is four chunks\n",
    "    These are never likely to be changed, maybe? : chunksize=2048, tempo_res=32\n",
    "    \n",
    "    TODO: make become on the fly\n",
    "    '''\n",
    "    # default value of onset, overwritten if onset is detected\n",
    "    onset = -1\n",
    "\n",
    "    # to detect difference\n",
    "    difference = np.cumsum(np.add(np.absolute(signal[chunksize:-chunksize]), -np.absolute(signal[:-2*chunksize])))\n",
    "    \n",
    "    # white noise is added the the difference \n",
    "    # this is to desensitise detection of low amplitdue onset sounds\n",
    "    noise = 10*np.array(np.random.randn(len(difference)))\n",
    "    difference = np.add(difference, noise)\n",
    "\n",
    "    # calculation of r-coefficient\n",
    "    # -1 is negatively correlated\n",
    "    # +1 is positively correlated\n",
    "    # onset is when r-coefficient cuts above 0.8\n",
    "    roceff = np.full(tempo_res, 0.)\n",
    "    tempo_num = int(chunksize / tempo_res)\n",
    "    for i in range(tempo_res):\n",
    "#         print(np.shape(difference))\n",
    "        roceff[i] = np.corrcoef(difference[i * tempo_num:(i * tempo_num + chunksize)],\n",
    "                                      np.arange(chunksize))[0, 1]\n",
    "        # special case when i = 0, because we do not have the previous value\n",
    "#         if i == 0 and roceff[0] > 0.8:\n",
    "#             onset = i\n",
    "        if roceff[0] < 0.8 and roceff[i] > 0.8 and np.max(roceff[:i]) < 0.8:\n",
    "            onset = i\n",
    "    \n",
    "    if onset != -1:\n",
    "        # clear output from jupyter\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(16,2))\n",
    "        plt.plot(np.arange(2048*1,2048*3),np.array(difference)/np.max(difference))\n",
    "        plt.plot(np.arange(2048*2,2048*3,64),roceff)\n",
    "        plt.plot(signal)\n",
    "        plt.axvline(x=2048*1+64*onset, color=\"r\")\n",
    "        plt.axvline(x=2048*3+64*onset, color=\"r\")\n",
    "        plt.show()\n",
    "    return onset # none, or a value\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def convert_to_CQT(signal_to_map):\n",
    "    fmin = librosa.core.note_to_hz(\"B3\")\n",
    "    cqt_array = librosa.cqt(signal_to_map, sr=44100, hop_length=2**7, bins_per_octave=36, fmin=fmin, n_bins=108)\n",
    "    CQT = librosa.magphase(cqt_array)[0][:108,-108:]\n",
    "    print(np.shape(CQT))\n",
    "    return CQT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "def setup_classifier(model_path, weight_path):\n",
    "    yaml_file = open(model_path, 'r')\n",
    "    loaded = yaml_file.read()\n",
    "    yaml_file.close()\n",
    "    classifier = keras.models.model_from_yaml(loaded)\n",
    "    classifier.load_weights(weight_path)\n",
    "    return classifier\n",
    "\n",
    "classifier = setup_classifier(model_path=\"model.yaml\", weight_path=\"weight-25800-CNN_E_good.hdf5\")\n",
    "# Loading the classifier takes time. It should not be done every time when the program runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, classifier):\n",
    "    result = classifier.predict(data)[0].tolist()\n",
    "    output = 'C'\n",
    "    possible = 'possible notes: '\n",
    "    for i in range(len(result)):\n",
    "        if result[i] < 0.01:\n",
    "            result[i] = 0\n",
    "        elif result[i] > 0.99:\n",
    "            result[i] = 1\n",
    "            output += '_{}'.format(i+60)\n",
    "        else:\n",
    "            possible += '_{}__{}'.format(i+60, result[i])\n",
    "    print(output)\n",
    "    print(possible)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = predict(spectro, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_detect(chunksize=2048, tempo_res=32, plotting = False):\n",
    "    print(\"opening\")\n",
    "    frames = []\n",
    "    i = 0\n",
    "\n",
    "    while True:\n",
    "        # assume pyaudio clip mono sound\n",
    "        # use assert?\n",
    "        \n",
    "        i += 1\n",
    "        data = stream.read(chunksize, exception_on_overflow=False)\n",
    "        data = np.fromstring(data, np.float32)\n",
    "        frames.append(data)\n",
    "        # print(len(frames))\n",
    "        \n",
    "        # start listening only after there is a certain number of \"frames\"\n",
    "        if i > 10 and len(frames)>4:\n",
    "            frames[:] = frames[-5:]\n",
    "            signal = np.concatenate((frames[-5],frames[-4],frames[-3],frames[-2]))\n",
    "            \n",
    "            # onset function\n",
    "            # print(np.sum(abs(signal)))\n",
    "            # print(len(signal))\n",
    "            # print(\"finding onset\")\n",
    "            onset = detect_onset(signal)\n",
    "            # print(\"onset detection complete\")\n",
    "            # print(onset)\n",
    "            \n",
    "            # remove the older frames\n",
    "            \n",
    "            \n",
    "            # make an array consists of 4096 entries if there is an onset\n",
    "            if onset != -1:\n",
    "                print(\"onset DETECTED\")\n",
    "                signal_ = np.concatenate((frames[-10:]))\n",
    "                signal_input = signal_[-4096*3+64*onset:4096+64*onset]\n",
    "                onset = -1 # set onset back to negative one - but necessary?\n",
    "                \n",
    "                spectro = convert_to_CQT(signal_input)\n",
    "                print(spectro)\n",
    "                \n",
    "                result = predict(spectro, classifier)\n",
    "                print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     note_detect(classifier, plotting = False)\n",
    "    \n",
    "\n",
    "# note_detect(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type Sequential)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f93d1b362244>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnote_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-3df7c6a4ad6b>\u001b[0m in \u001b[0;36mnote_detect\u001b[0;34m(chunksize, tempo_res, plotting)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/nd/lib/python3.6/site-packages/pyaudio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    606\u001b[0m                           paCanNotReadFromAnOutputOnlyStream)\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception_on_overflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_read_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type Sequential)"
     ]
    }
   ],
   "source": [
    "note_detect(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nd]",
   "language": "python",
   "name": "conda-env-nd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
