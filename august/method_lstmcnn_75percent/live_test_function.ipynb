{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_index = np.array(glob.glob('../preparations/spectrograms/*'))\n",
    "labels_index = np.array(glob.glob('../preparations/labels/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "height = 108\n",
    "width = 108\n",
    "steps = 20\n",
    "spec_list = spectrums_index[:num_samples]\n",
    "labe_list = labels_index[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate inputs to model\n",
    "\n",
    "def inputs_to_model(spectrum_list, labels_list, order, num, start, ending):\n",
    "    lstm_output = []\n",
    "    cnn_output = []\n",
    "    y_train = []\n",
    "    \n",
    "    import time\n",
    "    start_ = time.time()\n",
    "\n",
    "    for file in order[num][start:ending]:\n",
    "        spectrum = np.load(spectrum_list[file])\n",
    "        labels = np.load(labels_list[file])\n",
    "        \n",
    "        _lstm = np.zeros((20, 24))\n",
    "        for count, i in enumerate(labels):\n",
    "            _cnn = spectrum[:, 27*count:108+27*count]\n",
    "            if _cnn.shape == (height, width):\n",
    "                lstm_output.append(_lstm)\n",
    "                cnn_output.append(_cnn.reshape((height, width, 1)))\n",
    "                y_train.append(i)\n",
    "        \n",
    "            _lstm = _lstm[1:, :]\n",
    "            _lstm = np.append(_lstm, i.reshape((1, 24)), axis=0)\n",
    "        \n",
    "    lstm_inputs = np.array(lstm_output)\n",
    "    cnn_inputs = np.array(cnn_output)\n",
    "    labels_inputs = np.array(y_train)\n",
    "    print(time.time()-start_)\n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, 1), name='cnn_inputs')\n",
    "    layers = BatchNormalization()(cnn_inputs)\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = classifier_1(optimizer='adam')\n",
    "classifier.load_weights('weights/weight-75overlap-model1.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_prediction(classifier, weight_path, cnn_input, lstm_input):\n",
    "\n",
    "    classifier.load_weights(weight_path)\n",
    "    prediction = classifier.predict([cnn_input, lstm_input])\n",
    "    output = 'The notes are: C4'\n",
    "    for i in range(prediction.shape[0]):\n",
    "        for j in range(prediction.shape[1]):\n",
    "            if prediction[i][j] < 0.5:\n",
    "                prediction[i][j] = 0\n",
    "            elif prediction[i][j] > 0.5:\n",
    "                prediction[i][j] = 1\n",
    "                output+='_{}'.format(j+60)\n",
    "        print(output)\n",
    "    return prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
