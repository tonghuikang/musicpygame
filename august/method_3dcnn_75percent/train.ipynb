{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import gc\n",
    "import keras \n",
    "from keras.layers import LSTM, Dense, TimeDistributed, Dropout, MaxPooling2D, Conv2D, Input\n",
    "from keras.layers import Flatten, BatchNormalization, Activation, Reshape, concatenate\n",
    "from keras.models import Model\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "import keras.backend as K\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "gc.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrums_index = np.array(glob.glob('E:/notes_database/spectrograms_3d/*'))\n",
    "labels_index = np.array(glob.glob('../preparations/labels/*'))\n",
    "kf = KFold(n_splits=12, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5000\n",
    "height = 60\n",
    "width = 108\n",
    "channels = 2\n",
    "steps = 20\n",
    "spec_list = spectrums_index[:num_samples]\n",
    "labe_list = labels_index[:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_order = []\n",
    "test_order = []\n",
    "length = np.arange(num_samples)\n",
    "\n",
    "for x, y in kf.split(range(num_samples)):\n",
    "    train_order.append(length[x])\n",
    "    test_order.append(length[y])\n",
    "train_order = np.array(train_order)\n",
    "test_order = np.array(test_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_order[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_model(spectrum_list, labels_list, order, num, start, ending):\n",
    "    lstm_output = []\n",
    "    cnn_output = []\n",
    "    y_train = []\n",
    "    \n",
    "    import time\n",
    "    start_ = time.time()\n",
    "\n",
    "    for file in order[num][start:ending]:\n",
    "        spectrum = np.load(spectrum_list[file])\n",
    "        labels = np.load(labels_list[file])\n",
    "        \n",
    "        _lstm = np.zeros((20, 24))\n",
    "        for count, i in enumerate(labels):\n",
    "            _cnn = spectrum[:, 27*count:108+27*count, :]\n",
    "            if _cnn.shape == (60, 108, channels):\n",
    "                lstm_output.append(_lstm)\n",
    "                cnn_output.append(_cnn)\n",
    "                y_train.append(i)\n",
    "                \n",
    "            _lstm = _lstm[1:, :]\n",
    "            _lstm = np.append(_lstm, i.reshape((1, 24)), axis=0)\n",
    "        \n",
    "    lstm_inputs = np.array(lstm_output)\n",
    "    cnn_inputs = np.array(cnn_output)\n",
    "    labels_inputs = np.array(y_train)\n",
    "    print(time.time()-start_)\n",
    "    return lstm_inputs, cnn_inputs, labels_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.352017164230347\n"
     ]
    }
   ],
   "source": [
    "lstm_test, cnn_test, labels_test = inputs_to_model(spec_list, labe_list, test_order, 0, 0, test_order[0].shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_whole(classifier, num, name, spectrum_list, labels_list, epochs=100, batchsize=32):\n",
    "    lstm_inputs, cnn_inputs, labels_inputs = inputs_to_model(spectrum_list, labels_list, train_order, \n",
    "                                                             num, 0, train_order[num].shape[0]+1)\n",
    "\n",
    "    classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=epochs, batch_size=batchsize, verbose=1,\n",
    "                  validation_data = ([lstm_test, cnn_test], labels_test))\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)   \n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_part(classifier, num, name, spectrum_list, labels_list, epochs=100, batchsize=32, split=7):\n",
    "    \n",
    "    num_samples = train_order[num].shape[0]\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        for i in range(split):\n",
    "            lstm_inputs, cnn_inputs, labels_inputs = inputs_to_model(spectrum_list, labels_list, train_order, \n",
    "                                                                     num, num_samples//split*i, num_samples//split*(i+1))\n",
    "\n",
    "            classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=1, batch_size=batchsize, verbose=1,\n",
    "                          validation_data = ([lstm_test, cnn_test], labels_test))\n",
    "            gc.collect()\n",
    "    \n",
    "    classifier.save_weights(name, overwrite=True)   \n",
    "    del classifier\n",
    "    K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_1(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, channels), name='cnn_inputs')\n",
    "    layers = BatchNormalization()(cnn_inputs)\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.91341853141785\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 125s 2ms/step - loss: 0.0612 - acc: 0.9791 - val_loss: 0.0498 - val_acc: 0.9824\n",
      "47.82452726364136\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 139s 2ms/step - loss: 0.0423 - acc: 0.9836 - val_loss: 0.0380 - val_acc: 0.9851\n",
      "41.583988428115845\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 118s 2ms/step - loss: 0.0380 - acc: 0.9851 - val_loss: 0.0355 - val_acc: 0.9856\n",
      "37.57082486152649\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 118s 2ms/step - loss: 0.0354 - acc: 0.9859 - val_loss: 0.0320 - val_acc: 0.9870\n",
      "42.402684926986694\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 114s 2ms/step - loss: 0.0342 - acc: 0.9864 - val_loss: 0.0335 - val_acc: 0.9864\n",
      "44.673139810562134\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 116s 2ms/step - loss: 0.0327 - acc: 0.9868 - val_loss: 0.0380 - val_acc: 0.9857\n",
      "33.87262773513794\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 120s 2ms/step - loss: 0.0318 - acc: 0.9871 - val_loss: 0.0309 - val_acc: 0.9871\n",
      "32.691080808639526\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 114s 2ms/step - loss: 0.0314 - acc: 0.9872 - val_loss: 0.0290 - val_acc: 0.9884\n",
      "31.407038927078247\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 111s 2ms/step - loss: 0.0307 - acc: 0.9874 - val_loss: 0.0290 - val_acc: 0.9879\n",
      "50.95467948913574\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 115s 2ms/step - loss: 0.0302 - acc: 0.9877 - val_loss: 0.0297 - val_acc: 0.9878\n",
      "45.532026052474976\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 115s 2ms/step - loss: 0.0296 - acc: 0.9879 - val_loss: 0.0259 - val_acc: 0.9890\n",
      "40.36727738380432\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 110s 2ms/step - loss: 0.0292 - acc: 0.9881 - val_loss: 0.0274 - val_acc: 0.9884\n",
      "57.614033699035645\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 112s 2ms/step - loss: 0.0290 - acc: 0.9881 - val_loss: 0.0261 - val_acc: 0.9891\n",
      "43.96637725830078\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 109s 2ms/step - loss: 0.0283 - acc: 0.9883 - val_loss: 0.0267 - val_acc: 0.9887\n",
      "65.93017220497131\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0279 - acc: 0.9886 - val_loss: 0.0249 - val_acc: 0.9896\n",
      "39.12222862243652\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 111s 2ms/step - loss: 0.0276 - acc: 0.9885 - val_loss: 0.0264 - val_acc: 0.9890\n",
      "33.34401607513428\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 109s 2ms/step - loss: 0.0269 - acc: 0.9889 - val_loss: 0.0262 - val_acc: 0.9887\n",
      "35.37803912162781\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 116s 2ms/step - loss: 0.0275 - acc: 0.9886 - val_loss: 0.0266 - val_acc: 0.9892\n",
      "48.83692979812622\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 109s 2ms/step - loss: 0.0270 - acc: 0.9889 - val_loss: 0.0262 - val_acc: 0.9893\n",
      "31.51791763305664\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 109s 2ms/step - loss: 0.0268 - acc: 0.9890 - val_loss: 0.0239 - val_acc: 0.9899\n",
      "48.74741339683533\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 114s 2ms/step - loss: 0.0266 - acc: 0.9891 - val_loss: 0.0243 - val_acc: 0.9898\n",
      "41.209638595581055\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 106s 2ms/step - loss: 0.0264 - acc: 0.9891 - val_loss: 0.0315 - val_acc: 0.9874\n",
      "44.411450147628784\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 108s 2ms/step - loss: 0.0262 - acc: 0.9892 - val_loss: 0.0239 - val_acc: 0.9901\n",
      "45.67677927017212\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 108s 2ms/step - loss: 0.0258 - acc: 0.9892 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "45.37993931770325\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 106s 2ms/step - loss: 0.0257 - acc: 0.9893 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "38.03794717788696\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 114s 2ms/step - loss: 0.0254 - acc: 0.9895 - val_loss: 0.0248 - val_acc: 0.9899\n",
      "36.25573444366455\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 111s 2ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.0238 - val_acc: 0.9902\n",
      "32.23834705352783\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 109s 2ms/step - loss: 0.0254 - acc: 0.9894 - val_loss: 0.0230 - val_acc: 0.9904\n",
      "32.80440068244934\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 108s 2ms/step - loss: 0.0255 - acc: 0.9896 - val_loss: 0.0236 - val_acc: 0.9899\n",
      "33.554306507110596\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 111s 2ms/step - loss: 0.0253 - acc: 0.9895 - val_loss: 0.0265 - val_acc: 0.9890\n",
      "60.19289684295654\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 110s 2ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.0267 - val_acc: 0.9886\n",
      "40.55391812324524\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0251 - acc: 0.9895 - val_loss: 0.0241 - val_acc: 0.9901\n",
      "57.79893374443054\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0249 - acc: 0.9897 - val_loss: 0.0222 - val_acc: 0.9907\n",
      "39.287659645080566\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 109s 2ms/step - loss: 0.0244 - acc: 0.9899 - val_loss: 0.0253 - val_acc: 0.9896\n",
      "43.489792346954346\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0242 - acc: 0.9901 - val_loss: 0.0221 - val_acc: 0.9909\n",
      "53.971705198287964\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 107s 2ms/step - loss: 0.0240 - acc: 0.9901 - val_loss: 0.0226 - val_acc: 0.9904\n",
      "35.42918419837952\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0241 - acc: 0.9900 - val_loss: 0.0225 - val_acc: 0.9907\n",
      "32.30491638183594\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 105s 2ms/step - loss: 0.0243 - acc: 0.9899 - val_loss: 0.0237 - val_acc: 0.9900\n",
      "31.539472103118896\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 110s 2ms/step - loss: 0.0243 - acc: 0.9898 - val_loss: 0.0229 - val_acc: 0.9904\n",
      "36.522576332092285\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56352/56352 [==============================] - 114s 2ms/step - loss: 0.0243 - acc: 0.9900 - val_loss: 0.0223 - val_acc: 0.9906\n",
      "48.9572594165802\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 117s 2ms/step - loss: 0.0242 - acc: 0.9899 - val_loss: 0.0241 - val_acc: 0.9899\n",
      "37.16312575340271\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 115s 2ms/step - loss: 0.0241 - acc: 0.9899 - val_loss: 0.0225 - val_acc: 0.9906\n",
      "39.53759431838989\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 116s 2ms/step - loss: 0.0243 - acc: 0.9900 - val_loss: 0.0226 - val_acc: 0.9906\n",
      "36.66326880455017\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 110s 2ms/step - loss: 0.0237 - acc: 0.9902 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "45.2571702003479\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 112s 2ms/step - loss: 0.0233 - acc: 0.9904 - val_loss: 0.0223 - val_acc: 0.9910\n",
      "61.33877182006836\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 115s 2ms/step - loss: 0.0234 - acc: 0.9903 - val_loss: 0.0222 - val_acc: 0.9905\n",
      "36.14013075828552\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 110s 2ms/step - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0221 - val_acc: 0.9907\n",
      "33.73692560195923\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 108s 2ms/step - loss: 0.0235 - acc: 0.9901 - val_loss: 0.0232 - val_acc: 0.9905\n",
      "32.169729709625244\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 107s 2ms/step - loss: 0.0236 - acc: 0.9902 - val_loss: 0.0262 - val_acc: 0.9886\n",
      "33.48566794395447\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 108s 2ms/step - loss: 0.0235 - acc: 0.9902 - val_loss: 0.0222 - val_acc: 0.9907\n",
      "73.15096426010132\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0235 - acc: 0.9901 - val_loss: 0.0240 - val_acc: 0.9902\n",
      "36.68496346473694\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0236 - acc: 0.9901 - val_loss: 0.0226 - val_acc: 0.9905\n",
      "47.6330246925354\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0236 - acc: 0.9903 - val_loss: 0.0245 - val_acc: 0.9899\n",
      "39.58102583885193\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 110s 2ms/step - loss: 0.0230 - acc: 0.9903 - val_loss: 0.0217 - val_acc: 0.9906\n",
      "41.389296531677246\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0230 - acc: 0.9905 - val_loss: 0.0237 - val_acc: 0.9901\n",
      "189.5441176891327\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 108s 2ms/step - loss: 0.0228 - acc: 0.9906 - val_loss: 0.0209 - val_acc: 0.9911\n",
      "36.71019220352173\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0229 - acc: 0.9904 - val_loss: 0.0222 - val_acc: 0.9906\n",
      "31.74131441116333\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 110s 2ms/step - loss: 0.0231 - acc: 0.9902 - val_loss: 0.0207 - val_acc: 0.9914\n",
      "30.574689626693726\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 113s 2ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0214 - val_acc: 0.9910\n",
      "30.594439268112183\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 108s 2ms/step - loss: 0.0229 - acc: 0.9905 - val_loss: 0.0214 - val_acc: 0.9910\n",
      "45.34719204902649\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 109s 2ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0209 - val_acc: 0.9913\n",
      "35.3843252658844\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0229 - acc: 0.9904 - val_loss: 0.0255 - val_acc: 0.9903\n",
      "41.59350109100342\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 108s 2ms/step - loss: 0.0230 - acc: 0.9904 - val_loss: 0.0227 - val_acc: 0.9908\n",
      "36.91890859603882\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 112s 2ms/step - loss: 0.0225 - acc: 0.9905 - val_loss: 0.0213 - val_acc: 0.9910\n",
      "44.35596704483032\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0226 - val_acc: 0.9903\n",
      "42.35293936729431\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 114s 2ms/step - loss: 0.0224 - acc: 0.9906 - val_loss: 0.0214 - val_acc: 0.9909\n",
      "32.2779586315155\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 110s 2ms/step - loss: 0.0223 - acc: 0.9907 - val_loss: 0.0209 - val_acc: 0.9915\n",
      "32.86025357246399\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 109s 2ms/step - loss: 0.0226 - acc: 0.9906 - val_loss: 0.0204 - val_acc: 0.9914\n",
      "31.408353090286255\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 115s 2ms/step - loss: 0.0228 - acc: 0.9904 - val_loss: 0.0209 - val_acc: 0.9912\n",
      "31.62155771255493\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 111s 2ms/step - loss: 0.0227 - acc: 0.9905 - val_loss: 0.0224 - val_acc: 0.9905\n",
      "46.6367552280426\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0226 - acc: 0.9907 - val_loss: 0.0204 - val_acc: 0.9913\n",
      "39.37187480926514\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0225 - acc: 0.9904 - val_loss: 0.0223 - val_acc: 0.9910\n",
      "40.033634662628174\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 114s 2ms/step - loss: 0.0226 - acc: 0.9907 - val_loss: 0.0288 - val_acc: 0.9894\n",
      "47.94590401649475\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 106s 2ms/step - loss: 0.0220 - acc: 0.9907 - val_loss: 0.0215 - val_acc: 0.9910\n",
      "40.26256012916565\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 117s 2ms/step - loss: 0.0221 - acc: 0.9908 - val_loss: 0.0234 - val_acc: 0.9908\n",
      "37.28353404998779\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 106s 2ms/step - loss: 0.0220 - acc: 0.9908 - val_loss: 0.0208 - val_acc: 0.9914\n",
      "33.91084313392639\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 107s 2ms/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0213 - val_acc: 0.9909\n",
      "33.941489696502686\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 107s 2ms/step - loss: 0.0223 - acc: 0.9907 - val_loss: 0.0220 - val_acc: 0.9911\n",
      "32.946913957595825\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 109s 2ms/step - loss: 0.0224 - acc: 0.9906 - val_loss: 0.0205 - val_acc: 0.9915\n",
      "32.435590505599976\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56352/56352 [==============================] - 108s 2ms/step - loss: 0.0222 - acc: 0.9906 - val_loss: 0.0215 - val_acc: 0.9911\n",
      "61.79651141166687\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0221 - acc: 0.9908 - val_loss: 0.0220 - val_acc: 0.9911\n",
      "41.988269567489624\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0223 - acc: 0.9907 - val_loss: 0.0233 - val_acc: 0.9902\n",
      "62.39041471481323\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0221 - acc: 0.9907 - val_loss: 0.0201 - val_acc: 0.9916\n",
      "36.19110035896301\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 106s 2ms/step - loss: 0.0217 - acc: 0.9908 - val_loss: 0.0219 - val_acc: 0.9906\n",
      "39.87445783615112\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.0214 - val_acc: 0.9912\n",
      "40.51980209350586\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 110s 2ms/step - loss: 0.0215 - acc: 0.9911 - val_loss: 0.0258 - val_acc: 0.9902\n",
      "37.474966049194336\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 111s 2ms/step - loss: 0.0218 - acc: 0.9909 - val_loss: 0.0206 - val_acc: 0.9913\n",
      "34.157052516937256\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 122s 2ms/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0209 - val_acc: 0.9913\n",
      "31.851876974105835\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 112s 2ms/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0231 - val_acc: 0.9899\n",
      "32.54650139808655\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 111s 2ms/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0213 - val_acc: 0.9909\n",
      "48.09531092643738\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0220 - acc: 0.9907 - val_loss: 0.0212 - val_acc: 0.9910\n",
      "59.204585313797\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0199 - val_acc: 0.9917\n",
      "41.34964895248413\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0220 - acc: 0.9908 - val_loss: 0.0234 - val_acc: 0.9909\n",
      "35.80409622192383\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 107s 2ms/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0205 - val_acc: 0.9914\n",
      "38.86584973335266\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 105s 2ms/step - loss: 0.0217 - acc: 0.9909 - val_loss: 0.0221 - val_acc: 0.9909\n",
      "41.28718376159668\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 110s 2ms/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0218 - val_acc: 0.9908\n",
      "35.616639614105225\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.0197 - val_acc: 0.9917\n",
      "31.05518913269043\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 107s 2ms/step - loss: 0.0218 - acc: 0.9908 - val_loss: 0.0214 - val_acc: 0.9910\n",
      "32.52362298965454\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 124s 2ms/step - loss: 0.0218 - acc: 0.9908 - val_loss: 0.0204 - val_acc: 0.9914\n",
      "42.58365440368652\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 106s 2ms/step - loss: 0.0215 - acc: 0.9910 - val_loss: 0.0206 - val_acc: 0.9912\n",
      "51.987772941589355\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0218 - acc: 0.9909 - val_loss: 0.0200 - val_acc: 0.9916\n",
      "36.60078549385071\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 116s 2ms/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0210 - val_acc: 0.9910\n",
      "39.25640940666199\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 108s 2ms/step - loss: 0.0219 - acc: 0.9909 - val_loss: 0.0201 - val_acc: 0.9916\n",
      "38.2566454410553\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 106s 2ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "48.28389263153076\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0214 - acc: 0.9912 - val_loss: 0.0223 - val_acc: 0.9908\n",
      "68.90567469596863\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 106s 2ms/step - loss: 0.0213 - acc: 0.9911 - val_loss: 0.0247 - val_acc: 0.9907\n",
      "32.648566484451294\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0213 - acc: 0.9911 - val_loss: 0.0210 - val_acc: 0.9914\n",
      "32.92974400520325\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 107s 2ms/step - loss: 0.0213 - acc: 0.9910 - val_loss: 0.0205 - val_acc: 0.9914\n",
      "31.445744037628174\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 106s 2ms/step - loss: 0.0217 - acc: 0.9909 - val_loss: 0.0205 - val_acc: 0.9914\n",
      "31.758168935775757\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 107s 2ms/step - loss: 0.0215 - acc: 0.9911 - val_loss: 0.0209 - val_acc: 0.9911\n",
      "50.62871289253235\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0214 - acc: 0.9910 - val_loss: 0.0207 - val_acc: 0.9913\n",
      "36.694509983062744\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 111s 2ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.0204 - val_acc: 0.9915\n",
      "39.49070358276367\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 108s 2ms/step - loss: 0.0217 - acc: 0.9910 - val_loss: 0.0207 - val_acc: 0.9916\n",
      "36.63202619552612\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 107s 2ms/step - loss: 0.0211 - acc: 0.9911 - val_loss: 0.0202 - val_acc: 0.9915\n",
      "40.240554332733154\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0211 - acc: 0.9912 - val_loss: 0.0267 - val_acc: 0.9899\n",
      "40.22489333152771\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 107s 2ms/step - loss: 0.0211 - acc: 0.9911 - val_loss: 0.0212 - val_acc: 0.9912\n",
      "33.05474042892456\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 110s 2ms/step - loss: 0.0211 - acc: 0.9912 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "33.788957595825195\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 122s 2ms/step - loss: 0.0214 - acc: 0.9910 - val_loss: 0.0209 - val_acc: 0.9911\n",
      "43.11487865447998\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 107s 2ms/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0209 - val_acc: 0.9914\n",
      "31.086453199386597\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56352/56352 [==============================] - 107s 2ms/step - loss: 0.0213 - acc: 0.9912 - val_loss: 0.0197 - val_acc: 0.9917\n",
      "60.267000675201416\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.0197 - val_acc: 0.9917\n",
      "38.55345845222473\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0212 - acc: 0.9911 - val_loss: 0.0201 - val_acc: 0.9917\n",
      "43.0992374420166\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0213 - acc: 0.9912 - val_loss: 0.0218 - val_acc: 0.9908\n",
      "38.58469223976135\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 120s 2ms/step - loss: 0.0209 - acc: 0.9911 - val_loss: 0.0225 - val_acc: 0.9903\n",
      "50.61311340332031\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0209 - acc: 0.9914 - val_loss: 0.0204 - val_acc: 0.9914\n",
      "38.77212166786194\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 109s 2ms/step - loss: 0.0207 - acc: 0.9913 - val_loss: 0.0213 - val_acc: 0.9916\n",
      "33.50775980949402\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0208 - acc: 0.9914 - val_loss: 0.0199 - val_acc: 0.9917\n",
      "32.99215006828308\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 113s 2ms/step - loss: 0.0213 - acc: 0.9910 - val_loss: 0.0196 - val_acc: 0.9917\n",
      "32.19365954399109\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 109s 2ms/step - loss: 0.0216 - acc: 0.9910 - val_loss: 0.0208 - val_acc: 0.9912\n",
      "32.960912227630615\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 109s 2ms/step - loss: 0.0212 - acc: 0.9912 - val_loss: 0.0207 - val_acc: 0.9914\n",
      "53.831114292144775\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 107s 2ms/step - loss: 0.0211 - acc: 0.9911 - val_loss: 0.0208 - val_acc: 0.9911\n",
      "35.757208585739136\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 107s 2ms/step - loss: 0.0212 - acc: 0.9910 - val_loss: 0.0204 - val_acc: 0.9913\n",
      "42.08387303352356\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 109s 2ms/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0225 - val_acc: 0.9909\n",
      "48.45737600326538\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 108s 2ms/step - loss: 0.0207 - acc: 0.9914 - val_loss: 0.0201 - val_acc: 0.9914\n",
      "43.17735576629639\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0207 - acc: 0.9914 - val_loss: 0.0215 - val_acc: 0.9912\n",
      "39.35013747215271\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 107s 2ms/step - loss: 0.0207 - acc: 0.9913 - val_loss: 0.0207 - val_acc: 0.9912\n",
      "37.14752960205078\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 108s 2ms/step - loss: 0.0208 - acc: 0.9914 - val_loss: 0.0212 - val_acc: 0.9915\n",
      "35.9758996963501\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 108s 2ms/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0203 - val_acc: 0.9915\n",
      "33.929537296295166\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 109s 2ms/step - loss: 0.0211 - acc: 0.9911 - val_loss: 0.0268 - val_acc: 0.9903\n",
      "34.42942023277283\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 108s 2ms/step - loss: 0.0210 - acc: 0.9913 - val_loss: 0.0197 - val_acc: 0.9916\n",
      "58.92359471321106\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 108s 2ms/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0230 - val_acc: 0.9903\n",
      "51.050517320632935\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 108s 2ms/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0201 - val_acc: 0.9918\n",
      "47.816901206970215\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 107s 2ms/step - loss: 0.0210 - acc: 0.9912 - val_loss: 0.0202 - val_acc: 0.9919\n",
      "47.64506387710571\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 108s 2ms/step - loss: 0.0207 - acc: 0.9913 - val_loss: 0.0205 - val_acc: 0.9914\n",
      "51.40980935096741\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 109s 2ms/step - loss: 0.0205 - acc: 0.9915 - val_loss: 0.0217 - val_acc: 0.9910\n",
      "39.771915912628174\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 108s 2ms/step - loss: 0.0206 - acc: 0.9914 - val_loss: 0.0198 - val_acc: 0.9918\n",
      "33.773321866989136\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 107s 2ms/step - loss: 0.0204 - acc: 0.9915 - val_loss: 0.0222 - val_acc: 0.9910\n",
      "61.86048078536987\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 106s 2ms/step - loss: 0.0208 - acc: 0.9912 - val_loss: 0.0206 - val_acc: 0.9914\n",
      "99.75773215293884\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 115s 2ms/step - loss: 0.0209 - acc: 0.9913 - val_loss: 0.0205 - val_acc: 0.9913\n",
      "32.55485963821411\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 110s 2ms/step - loss: 0.0209 - acc: 0.9912 - val_loss: 0.0205 - val_acc: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "31524"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_1(optimizer=adam)\n",
    "train_test_part(classifier, 0, 'weights/weight-cnn3d-model1.hdf5', spec_list, labe_list, epochs=15, split=10)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:9: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.68173003196716\n",
      "Train on 81980 samples, validate on 41105 samples\n",
      "Epoch 1/10\n",
      "81980/81980 [==============================] - 197s 2ms/step - loss: 0.0643 - acc: 0.9780 - val_loss: 0.0666 - val_acc: 0.9804\n",
      "Epoch 2/10\n",
      "81980/81980 [==============================] - 172s 2ms/step - loss: 0.0410 - acc: 0.9838 - val_loss: 0.0827 - val_acc: 0.9806\n",
      "Epoch 3/10\n",
      "  160/81980 [..............................] - ETA: 1:18:13 - loss: 0.0332 - acc: 0.9859"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\callbacks.py:120: UserWarning: Method on_batch_end() is slow compared to the batch update (0.120193). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81980/81980 [==============================] - 292s 4ms/step - loss: 0.0373 - acc: 0.9852 - val_loss: 0.0430 - val_acc: 0.9847\n",
      "Epoch 4/10\n",
      "81980/81980 [==============================] - 287s 4ms/step - loss: 0.0348 - acc: 0.9862 - val_loss: 0.0330 - val_acc: 0.9868\n",
      "Epoch 5/10\n",
      "81980/81980 [==============================] - 292s 4ms/step - loss: 0.0334 - acc: 0.9867 - val_loss: 0.0332 - val_acc: 0.9864\n",
      "Epoch 6/10\n",
      " 6368/81980 [=>............................] - ETA: 4:16 - loss: 0.0324 - acc: 0.9871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-25-b042a7f6a73b>\", line 3, in <module>\n",
      "    train_test_whole(classifier, 0, 'weights/weight-75overlap-model1-rmsprop.hdf5', spec_list, labe_list, epochs=10)\n",
      "  File \"<ipython-input-23-e4086b015576>\", line 6, in train_test_whole\n",
      "    validation_data = ([lstm_test, cnn_test], labels_test))\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1705, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\", line 1235, in _fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2478, in __call__\n",
      "    **self.session_kwargs)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1104, in _run\n",
      "    np_val = np.asarray(subfeed_val, dtype=subfeed_dtype)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\numpy\\core\\numeric.py\", line 492, in asarray\n",
      "    return array(a, dtype, copy=False, order=order)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\inspect.py\", line 710, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "rmsprop = keras.optimizers.RMSprop()\n",
    "classifier = classifier_1(optimizer=rmsprop)\n",
    "train_test_whole(classifier, 0, 'weights/weight-75overlap-model1-rmsprop.hdf5', spec_list, labe_list, epochs=10)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_3(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, channels), name='cnn_inputs')\n",
    "    layers = Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(cnn_inputs)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.61816191673279\n",
      "Train on 81980 samples, validate on 41105 samples\n",
      "Epoch 1/5\n",
      "81980/81980 [==============================] - 192s 2ms/step - loss: 0.0537 - acc: 0.9806 - val_loss: 0.0477 - val_acc: 0.9834\n",
      "Epoch 2/5\n",
      "81980/81980 [==============================] - 373s 5ms/step - loss: 0.0371 - acc: 0.9854 - val_loss: 0.0383 - val_acc: 0.9844\n",
      "Epoch 3/5\n",
      "81980/81980 [==============================] - 257s 3ms/step - loss: 0.0331 - acc: 0.9866 - val_loss: 0.0314 - val_acc: 0.9874\n",
      "Epoch 4/5\n",
      "81980/81980 [==============================] - 285s 3ms/step - loss: 0.0308 - acc: 0.9874 - val_loss: 0.0348 - val_acc: 0.9860\n",
      "Epoch 5/5\n",
      "81980/81980 [==============================] - 242s 3ms/step - loss: 0.0288 - acc: 0.9881 - val_loss: 0.0307 - val_acc: 0.9875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15762"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_3(optimizer=adam)\n",
    "train_test_whole(classifier, 0, 'weights/weight-75overlap-model3.hdf5', spec_list, labe_list, epochs=5)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.80060887336731\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 102s 2ms/step - loss: 0.0590 - acc: 0.9792 - val_loss: 0.0457 - val_acc: 0.9832\n",
      "48.01833915710449\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 127s 2ms/step - loss: 0.0403 - acc: 0.9843 - val_loss: 0.0370 - val_acc: 0.9857\n",
      "47.20769906044006\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 137s 2ms/step - loss: 0.0368 - acc: 0.9855 - val_loss: 0.0369 - val_acc: 0.9850\n",
      "46.05168914794922\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 120s 2ms/step - loss: 0.0344 - acc: 0.9863 - val_loss: 0.0323 - val_acc: 0.9869\n",
      "40.14682626724243\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 132s 2ms/step - loss: 0.0330 - acc: 0.9869 - val_loss: 0.0311 - val_acc: 0.9874\n",
      "43.09801912307739\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 114s 2ms/step - loss: 0.0318 - acc: 0.9872 - val_loss: 0.0344 - val_acc: 0.9870\n",
      "34.2732048034668\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 109s 2ms/step - loss: 0.0312 - acc: 0.9874 - val_loss: 0.0341 - val_acc: 0.9868\n",
      "33.14848470687866\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 114s 2ms/step - loss: 0.0307 - acc: 0.9875 - val_loss: 0.0272 - val_acc: 0.9887\n",
      "33.367167711257935\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 119s 2ms/step - loss: 0.0300 - acc: 0.9877 - val_loss: 0.0279 - val_acc: 0.9885\n",
      "34.03888416290283\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 111s 2ms/step - loss: 0.0294 - acc: 0.9881 - val_loss: 0.0267 - val_acc: 0.9889\n",
      "85.46421957015991\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 109s 2ms/step - loss: 0.0292 - acc: 0.9881 - val_loss: 0.0269 - val_acc: 0.9890\n",
      "50.377156019210815\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 109s 2ms/step - loss: 0.0286 - acc: 0.9883 - val_loss: 0.0257 - val_acc: 0.9894\n",
      "42.61499619483948\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 115s 2ms/step - loss: 0.0283 - acc: 0.9886 - val_loss: 0.0291 - val_acc: 0.9878\n",
      "36.78823709487915\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 118s 2ms/step - loss: 0.0275 - acc: 0.9887 - val_loss: 0.0252 - val_acc: 0.9895\n",
      "40.55298066139221\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 110s 2ms/step - loss: 0.0274 - acc: 0.9888 - val_loss: 0.0260 - val_acc: 0.9889\n",
      "41.63085317611694\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 110s 2ms/step - loss: 0.0270 - acc: 0.9889 - val_loss: 0.0250 - val_acc: 0.9896\n",
      "33.601487159729004\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 114s 2ms/step - loss: 0.0268 - acc: 0.9889 - val_loss: 0.0277 - val_acc: 0.9880\n",
      "33.05474019050598\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 115s 2ms/step - loss: 0.0269 - acc: 0.9888 - val_loss: 0.0259 - val_acc: 0.9889\n",
      "31.461365699768066\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 110s 2ms/step - loss: 0.0266 - acc: 0.9890 - val_loss: 0.0239 - val_acc: 0.9900\n",
      "35.60101652145386\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 120s 2ms/step - loss: 0.0263 - acc: 0.9891 - val_loss: 0.0237 - val_acc: 0.9899\n",
      "46.129796504974365\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 118s 2ms/step - loss: 0.0262 - acc: 0.9891 - val_loss: 0.0237 - val_acc: 0.9901\n",
      "41.41215395927429\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 122s 2ms/step - loss: 0.0264 - acc: 0.9891 - val_loss: 0.0235 - val_acc: 0.9900\n",
      "43.66162610054016\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 111s 2ms/step - loss: 0.0257 - acc: 0.9893 - val_loss: 0.0231 - val_acc: 0.9903\n",
      "40.27179670333862\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 111s 2ms/step - loss: 0.0255 - acc: 0.9894 - val_loss: 0.0243 - val_acc: 0.9896\n",
      "41.89641547203064\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 118s 2ms/step - loss: 0.0253 - acc: 0.9897 - val_loss: 0.0237 - val_acc: 0.9902\n",
      "39.3813796043396\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 114s 2ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.0225 - val_acc: 0.9905\n",
      "40.47487258911133\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 111s 2ms/step - loss: 0.0249 - acc: 0.9897 - val_loss: 0.0229 - val_acc: 0.9903\n",
      "36.038413763046265\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 111s 2ms/step - loss: 0.0251 - acc: 0.9896 - val_loss: 0.0236 - val_acc: 0.9901\n",
      "36.8851683139801\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 110s 2ms/step - loss: 0.0249 - acc: 0.9896 - val_loss: 0.0236 - val_acc: 0.9900\n",
      "35.69474673271179\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 109s 2ms/step - loss: 0.0246 - acc: 0.9898 - val_loss: 0.0259 - val_acc: 0.9895\n",
      "49.988263845443726\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 118s 2ms/step - loss: 0.0247 - acc: 0.9896 - val_loss: 0.0264 - val_acc: 0.9899\n",
      "51.534777879714966\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 110s 2ms/step - loss: 0.0245 - acc: 0.9897 - val_loss: 0.0256 - val_acc: 0.9900\n",
      "54.674665212631226\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 111s 2ms/step - loss: 0.0248 - acc: 0.9897 - val_loss: 0.0225 - val_acc: 0.9906\n",
      "42.302568435668945\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 110s 2ms/step - loss: 0.0240 - acc: 0.9899 - val_loss: 0.0259 - val_acc: 0.9889\n",
      "64.99865436553955\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 110s 2ms/step - loss: 0.0239 - acc: 0.9901 - val_loss: 0.0235 - val_acc: 0.9902\n",
      "56.03372073173523\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 109s 2ms/step - loss: 0.0239 - acc: 0.9901 - val_loss: 0.0224 - val_acc: 0.9904\n",
      "36.11652135848999\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 114s 2ms/step - loss: 0.0236 - acc: 0.9902 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "32.945390701293945\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 121s 2ms/step - loss: 0.0244 - acc: 0.9899 - val_loss: 0.0235 - val_acc: 0.9905\n",
      "33.17971158027649\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 112s 2ms/step - loss: 0.0241 - acc: 0.9900 - val_loss: 0.0231 - val_acc: 0.9905\n",
      "35.99155139923096\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56352/56352 [==============================] - 118s 2ms/step - loss: 0.0238 - acc: 0.9902 - val_loss: 0.0276 - val_acc: 0.9881\n",
      "57.51612591743469\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 110s 2ms/step - loss: 0.0240 - acc: 0.9899 - val_loss: 0.0216 - val_acc: 0.9907\n",
      "37.600547552108765\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 119s 2ms/step - loss: 0.0240 - acc: 0.9899 - val_loss: 0.0216 - val_acc: 0.9910\n",
      "41.146591901779175\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 110s 2ms/step - loss: 0.0238 - acc: 0.9901 - val_loss: 0.0226 - val_acc: 0.9905\n",
      "64.15681409835815\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 113s 2ms/step - loss: 0.0236 - acc: 0.9900 - val_loss: 0.0287 - val_acc: 0.9887\n",
      "42.583752393722534\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 111s 2ms/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0219 - val_acc: 0.9909\n",
      "41.037240982055664\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 113s 2ms/step - loss: 0.0233 - acc: 0.9902 - val_loss: 0.0221 - val_acc: 0.9908\n",
      "35.536919832229614\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 110s 2ms/step - loss: 0.0232 - acc: 0.9905 - val_loss: 0.0220 - val_acc: 0.9910\n",
      "33.742080211639404\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 119s 2ms/step - loss: 0.0236 - acc: 0.9900 - val_loss: 0.0233 - val_acc: 0.9903\n",
      "32.7110710144043\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 112s 2ms/step - loss: 0.0235 - acc: 0.9901 - val_loss: 0.0314 - val_acc: 0.9870\n",
      "34.50752282142639\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 113s 2ms/step - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0234 - val_acc: 0.9902\n",
      "46.36411762237549\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 117s 2ms/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0224 - val_acc: 0.9907\n",
      "40.31866145133972\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 112s 2ms/step - loss: 0.0235 - acc: 0.9902 - val_loss: 0.0269 - val_acc: 0.9889\n",
      "47.70755124092102\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 111s 2ms/step - loss: 0.0234 - acc: 0.9902 - val_loss: 0.0212 - val_acc: 0.9911\n",
      "47.629443645477295\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 111s 2ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0233 - val_acc: 0.9901\n",
      "49.785205364227295\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 109s 2ms/step - loss: 0.0227 - acc: 0.9906 - val_loss: 0.0229 - val_acc: 0.9905\n",
      "60.360830545425415\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 110s 2ms/step - loss: 0.0229 - acc: 0.9903 - val_loss: 0.0217 - val_acc: 0.9908\n",
      "38.58469271659851\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 109s 2ms/step - loss: 0.0224 - acc: 0.9906 - val_loss: 0.0233 - val_acc: 0.9902\n",
      "66.3750433921814\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 111s 2ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0223 - val_acc: 0.9907\n",
      "34.08574843406677\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 111s 2ms/step - loss: 0.0233 - acc: 0.9903 - val_loss: 0.0220 - val_acc: 0.9907\n",
      "38.178536891937256\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 109s 2ms/step - loss: 0.0230 - acc: 0.9904 - val_loss: 0.0212 - val_acc: 0.9910\n",
      "68.92132186889648\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 115s 2ms/step - loss: 0.0229 - acc: 0.9904 - val_loss: 0.0229 - val_acc: 0.9901\n",
      "47.7383029460907\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 112s 2ms/step - loss: 0.0231 - acc: 0.9904 - val_loss: 0.0231 - val_acc: 0.9907\n",
      "40.46193790435791\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 114s 2ms/step - loss: 0.0230 - acc: 0.9905 - val_loss: 0.0232 - val_acc: 0.9904\n",
      "37.091803312301636\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 123s 2ms/step - loss: 0.0225 - acc: 0.9905 - val_loss: 0.0249 - val_acc: 0.9893\n",
      "42.050904989242554\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 117s 2ms/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0211 - val_acc: 0.9911\n",
      "62.67501187324524\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 115s 2ms/step - loss: 0.0226 - acc: 0.9905 - val_loss: 0.0213 - val_acc: 0.9910\n",
      "43.83720374107361\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 114s 2ms/step - loss: 0.0222 - acc: 0.9908 - val_loss: 0.0231 - val_acc: 0.9901\n",
      "37.74113965034485\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 111s 2ms/step - loss: 0.0226 - acc: 0.9906 - val_loss: 0.0221 - val_acc: 0.9909\n",
      "34.13261342048645\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 112s 2ms/step - loss: 0.0226 - acc: 0.9905 - val_loss: 0.0218 - val_acc: 0.9910\n",
      "36.02279281616211\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56352/56352 [==============================] - 111s 2ms/step - loss: 0.0227 - acc: 0.9905 - val_loss: 0.0233 - val_acc: 0.9902\n",
      "59.34544229507446\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 110s 2ms/step - loss: 0.0225 - acc: 0.9906 - val_loss: 0.0239 - val_acc: 0.9907\n",
      "36.9444534778595\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 117s 2ms/step - loss: 0.0227 - acc: 0.9905 - val_loss: 0.0212 - val_acc: 0.9911\n",
      "41.02162051200867\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 127s 2ms/step - loss: 0.0224 - acc: 0.9907 - val_loss: 0.0220 - val_acc: 0.9908\n",
      "39.01463580131531\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 117s 2ms/step - loss: 0.0222 - acc: 0.9907 - val_loss: 0.0221 - val_acc: 0.9906\n",
      "40.99037718772888\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 112s 2ms/step - loss: 0.0221 - acc: 0.9909 - val_loss: 0.0210 - val_acc: 0.9913\n",
      "39.72504925727844\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56382/56382 [==============================] - 115s 2ms/step - loss: 0.0223 - acc: 0.9907 - val_loss: 0.0212 - val_acc: 0.9911\n",
      "35.846126556396484\n",
      "Train on 56392 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56392/56392 [==============================] - 142s 3ms/step - loss: 0.0221 - acc: 0.9907 - val_loss: 0.0218 - val_acc: 0.9909\n",
      "37.460076093673706\n",
      "Train on 56393 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56393/56393 [==============================] - 135s 2ms/step - loss: 0.0224 - acc: 0.9907 - val_loss: 0.0211 - val_acc: 0.9911\n",
      "82.78803443908691\n",
      "Train on 56378 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56378/56378 [==============================] - 134s 2ms/step - loss: 0.0228 - acc: 0.9905 - val_loss: 0.0216 - val_acc: 0.9910\n",
      "32.23307991027832\n",
      "Train on 56352 samples, validate on 51317 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56352/56352 [==============================] - 119s 2ms/step - loss: 0.0224 - acc: 0.9907 - val_loss: 0.0218 - val_acc: 0.9911\n",
      "81.10596132278442\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 126s 2ms/step - loss: 0.0221 - acc: 0.9907 - val_loss: 0.0217 - val_acc: 0.9911\n",
      "40.9621684551239\n",
      "Train on 56397 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56397/56397 [==============================] - 149s 3ms/step - loss: 0.0223 - acc: 0.9906 - val_loss: 0.0218 - val_acc: 0.9906\n",
      "44.28649020195007\n",
      "Train on 56390 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56390/56390 [==============================] - 138s 2ms/step - loss: 0.0223 - acc: 0.9908 - val_loss: 0.0222 - val_acc: 0.9908\n",
      "40.068692207336426\n",
      "Train on 56402 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56402/56402 [==============================] - 135s 2ms/step - loss: 0.0219 - acc: 0.9908 - val_loss: 0.0222 - val_acc: 0.9908\n",
      "43.70849084854126\n",
      "Train on 56374 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "56374/56374 [==============================] - 123s 2ms/step - loss: 0.0219 - acc: 0.9910 - val_loss: 0.0213 - val_acc: 0.9913\n",
      "42.739967346191406\n",
      "Train on 56382 samples, validate on 51317 samples\n",
      "Epoch 1/1\n",
      "42912/56382 [=====================>........] - ETA: 23s - loss: 0.0220 - acc: 0.9908"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-234fb5be9f8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_test_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weight-cnn3d-model3.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabe_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-c0c9d89f060e>\u001b[0m in \u001b[0;36mtrain_test_part\u001b[1;34m(classifier, num, name, spectrum_list, labels_list, epochs, batchsize, split)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=1, batch_size=batchsize, verbose=1,\n\u001b[1;32m---> 11\u001b[1;33m                           validation_data = ([lstm_test, cnn_test], labels_test))\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_3(optimizer=adam)\n",
    "train_test_part(classifier, 0, 'weights/weight-cnn3d-model3.hdf5', spec_list, labe_list, epochs=15, split=10)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_4(optimizer='adam', loss='binary_crossentropy', metrix='accuracy'):\n",
    "    #cnn\n",
    "    cnn_inputs = Input(shape=(height, width, channels), name='cnn_inputs')\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(cnn_inputs)\n",
    "    layers = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(layers)\n",
    "    layers = BatchNormalization()(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = MaxPooling2D(2,2, border_mode='same')(layers)\n",
    "    layers = Conv2D(32, (3,3), activation='relu')(layers)\n",
    "    layers = Flatten()(layers)\n",
    "    layers = Dropout(0.3)(layers)\n",
    "    layers = Dense(32, activation='relu')(layers)\n",
    "    \n",
    "    #lstm\n",
    "    lstm_inputs = Input(shape=(steps, 24), name='lstm_inputs')\n",
    "    lstm_layers = LSTM(16, return_sequences=True)(lstm_inputs)\n",
    "    lstm_layers = LSTM(16)(lstm_layers)\n",
    "    lstm_layers = Dense(24, activation='relu')(lstm_layers)\n",
    "    \n",
    "    #main route\n",
    "    main_ = concatenate([lstm_layers, layers])\n",
    "    main_ = BatchNormalization()(main_)\n",
    "    main_ = Dense(64, activation='relu')(main_)\n",
    "    output = Dense(24, activation='sigmoid')(main_)\n",
    "    \n",
    "    model = Model(inputs=[lstm_inputs, cnn_inputs], outputs=[output])\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metrix])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  after removing the cwd from sys.path.\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(2, 2, padding=\"same\")`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.38756227493286\n",
      "Train on 81980 samples, validate on 41105 samples\n",
      "Epoch 1/5\n",
      "81980/81980 [==============================] - 169s 2ms/step - loss: 0.0621 - acc: 0.9788 - val_loss: 0.0470 - val_acc: 0.9823\n",
      "Epoch 2/5\n",
      "81980/81980 [==============================] - 207s 3ms/step - loss: 0.0438 - acc: 0.9832 - val_loss: 0.0407 - val_acc: 0.9839\n",
      "Epoch 3/5\n",
      "81980/81980 [==============================] - 169s 2ms/step - loss: 0.0393 - acc: 0.9847 - val_loss: 0.0355 - val_acc: 0.9858\n",
      "Epoch 4/5\n",
      "18368/81980 [=====>........................] - ETA: 1:49 - loss: 0.0375 - acc: 0.9853"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-353fd9906e97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0madam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_test_whole\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights/weight-75overlap-model4.hdf5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspec_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabe_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e4086b015576>\u001b[0m in \u001b[0;36mtrain_test_whole\u001b[1;34m(classifier, num, name, spectrum_list, labels_list, epochs, batchsize)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     classifier.fit([lstm_inputs, cnn_inputs], labels_inputs, epochs=epochs, batch_size=batchsize, verbose=1,\n\u001b[1;32m----> 6\u001b[1;33m                   validation_data = ([lstm_test, cnn_test], labels_test))\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                         \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mt_before_callbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdelta_t_median\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delta_ts_batch_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 331\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m             \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.005)\n",
    "classifier = classifier_4(optimizer=adam)\n",
    "train_test_whole(classifier, 0, 'weights/weight-75overlap-model4.hdf5', spec_list, labe_list, epochs=5)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
