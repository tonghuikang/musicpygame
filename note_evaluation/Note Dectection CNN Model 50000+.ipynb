{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras import callbacks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_row = 108\n",
    "img_col = 108\n",
    "path = \"E:/database108/\"\n",
    "batch_size = 64\n",
    "output_classes = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log10, floor\n",
    "def sig(number, sig=2):\n",
    "    if number == 0:\n",
    "        return 0\n",
    "    return round(number, sig - floor(log10(abs(number))) - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 11666)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file = pd.read_csv(path + \"database_517.csv\")\n",
    "array = file.values\n",
    "print(array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-bbdb94fab2c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mlst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m11665\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[1;31m#x = sig(float(x), 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "x_train_ori = []\n",
    "y_train_ori = []\n",
    "x_test_ori = []\n",
    "y_test_ori = []\n",
    "for i in range(516):\n",
    "    print(i)\n",
    "    file = pd.read_csv(path + \"database_{}.csv\".format(i), dtype=str)\n",
    "    array = file.values\n",
    "    array = list(array)\n",
    "    train_test = random.sample(range(100), 100)\n",
    "    \n",
    "    for j in train_test[:90]:\n",
    "        sample = list(array[j])\n",
    "        lst = []\n",
    "        for x in sample[1:11665]:\n",
    "            if type(x) == str:\n",
    "                x = \"\".join(x.split())\n",
    "                #x = sig(float(x), 3)\n",
    "                lst.append(float(x))\n",
    "            elif type(x) == float:\n",
    "                #x = sig(x, 3)\n",
    "                lst.append(x)\n",
    "            else:\n",
    "                print(type(x))\n",
    "        x_train_ori.append(lst)\n",
    "        y_train_ori.append(sample[0])\n",
    "        \n",
    "    for j in train_test[:90]:\n",
    "        sample = list(array[j])\n",
    "        lst = []\n",
    "        for x in sample[1:11665]:\n",
    "            if type(x) == str:\n",
    "                x = \"\".join(x.split())\n",
    "                #x = sig(float(x), 3)\n",
    "                lst.append(x)\n",
    "            elif type(x) == float:\n",
    "                #x = sig(x, 3)\n",
    "                lst.append(float(x))\n",
    "            else:\n",
    "                print(type(x))\n",
    "        x_train_ori.append(lst)\n",
    "        y_train_ori.append(sample[0])\n",
    "    \n",
    "    file = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25800, 13176)\n",
      "(5160, 13176)\n",
      "(25800,)\n",
      "(5160,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_train_ori))\n",
    "print(np.shape(x_test_ori))\n",
    "print(np.shape(y_train_ori))\n",
    "print(np.shape(y_test_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_convert(array, flag=0):\n",
    "    y = []\n",
    "    for i in array: # i is the name of each sample:\n",
    "        name = i.split(\"_\")\n",
    "        name = name[1:5]\n",
    "        if flag == 0:\n",
    "            # category of appearance of a note\n",
    "            category = np.zeros(24, dtype=int)\n",
    "            for j in name:\n",
    "                if j != \"x\":\n",
    "                    num = int(j)\n",
    "                    category[num-60] = 1\n",
    "            y.append(list(category))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_1 = []\n",
    "lst_2 = []\n",
    "\n",
    "for i in y_train_ori:\n",
    "    label = \"\".join(i.split())\n",
    "    lst_1.append(label)\n",
    "for j in y_test_ori:\n",
    "    label = \"\".join(j.split())\n",
    "    lst_2.append(label)\n",
    "    \n",
    "y_train_ori = y_convert(lst_1)\n",
    "y_test_ori = y_convert(lst_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ori = np.array(y_train_ori)\n",
    "y_test_ori = np.array(y_test_ori)\n",
    "x_train_ori = np.array(x_train_ori)\n",
    "x_test_ori = np.array(x_test_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_ori = x_train_ori.flatten()\n",
    "x_train_ori = x_train_ori.reshape(25800, img_row, img_col, 1)\n",
    "x_test_ori = x_test_ori.flatten()\n",
    "x_test_ori = x_test_ori.reshape(5160, img_row, img_col, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25800, 108, 122, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_ori.shape)\n",
    "input_shape = (108, 122, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    filename = \"model_train.csv\"\n",
    "    csv_log = callbacks.CSVLogger(filename, separator=\",\", append=False)\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=1, mode=\"min\")\n",
    "    \n",
    "    filepath = \"Best-weights-my_model-{epoch:03d}-{loss:4f}-{acc:4f}.hdf5\"\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only= True, mode=\"min\")\n",
    "    \n",
    "    callbacks_list = [csv_log, early_stop, checkpoint]\n",
    "    \n",
    "    #build the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), input_shape=input_shape, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #second convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), activation=\"relu\", border_mode=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #third convolutional layer\n",
    "    model.add(Conv2D(64, (3,3), activation=\"relu\", border_mode = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #first FC layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(24, activation=\"softmax\", kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25800 samples, validate on 5160 samples\n",
      "Epoch 1/100\n",
      "25800/25800 [==============================] - 22s 861us/step - loss: 12.4227 - acc: 0.0439 - val_loss: 18.6376 - val_acc: 0.0539\n",
      "Epoch 2/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.2350 - acc: 0.0424 - val_loss: 31.9129 - val_acc: 1.9380e-04\n",
      "Epoch 3/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.1625 - acc: 0.0421 - val_loss: 42.1439 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.1245 - acc: 0.0406 - val_loss: 44.5855 - val_acc: 0.1581\n",
      "Epoch 5/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.1132 - acc: 0.0389 - val_loss: 49.0933 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.1022 - acc: 0.0441 - val_loss: 51.5481 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.1004 - acc: 0.0433 - val_loss: 52.9501 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0974 - acc: 0.0440 - val_loss: 45.6477 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0944 - acc: 0.0444 - val_loss: 55.1217 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0972 - acc: 0.0401 - val_loss: 53.8964 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0963 - acc: 0.0426 - val_loss: 49.3458 - val_acc: 0.1581\n",
      "Epoch 12/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0974 - acc: 0.0410 - val_loss: 54.7956 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0942 - acc: 0.0446 - val_loss: 54.4644 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0964 - acc: 0.0419 - val_loss: 56.4959 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0964 - acc: 0.0390 - val_loss: 55.3322 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0955 - acc: 0.0424 - val_loss: 47.9758 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0959 - acc: 0.0423 - val_loss: 54.2380 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0961 - acc: 0.0461 - val_loss: 55.2822 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0975 - acc: 0.0433 - val_loss: 47.9309 - val_acc: 0.1581\n",
      "Epoch 20/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0970 - acc: 0.0443 - val_loss: 48.0622 - val_acc: 0.0359\n",
      "Epoch 21/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0942 - acc: 0.0475 - val_loss: 50.8129 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0943 - acc: 0.0438 - val_loss: 53.4090 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0966 - acc: 0.0432 - val_loss: 54.6093 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0965 - acc: 0.0438 - val_loss: 53.8387 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0959 - acc: 0.0403 - val_loss: 53.1457 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0964 - acc: 0.0450 - val_loss: 54.6007 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0942 - acc: 0.0426 - val_loss: 53.5722 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0942 - acc: 0.0416 - val_loss: 53.7368 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0953 - acc: 0.0400 - val_loss: 52.8371 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0948 - acc: 0.0429 - val_loss: 53.0026 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0956 - acc: 0.0440 - val_loss: 51.7441 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "25800/25800 [==============================] - 19s 727us/step - loss: 12.0956 - acc: 0.0428 - val_loss: 55.9547 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0955 - acc: 0.0385 - val_loss: 55.4444 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0941 - acc: 0.0388 - val_loss: 53.2398 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0939 - acc: 0.0454 - val_loss: 56.0411 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0963 - acc: 0.0392 - val_loss: 56.4460 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0938 - acc: 0.0414 - val_loss: 55.5589 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.0933 - acc: 0.0421 - val_loss: 54.7436 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.0961 - acc: 0.0414 - val_loss: 56.0297 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.0939 - acc: 0.0453 - val_loss: 56.3803 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0961 - acc: 0.0440 - val_loss: 55.6353 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.0948 - acc: 0.0412 - val_loss: 55.5735 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0937 - acc: 0.0453 - val_loss: 56.3929 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0939 - acc: 0.0435 - val_loss: 56.9303 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0952 - acc: 0.0437 - val_loss: 55.6636 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0937 - acc: 0.0441 - val_loss: 57.5028 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0949 - acc: 0.0428 - val_loss: 56.3010 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0959 - acc: 0.0417 - val_loss: 56.9140 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0951 - acc: 0.0424 - val_loss: 56.1334 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0958 - acc: 0.0363 - val_loss: 55.6932 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0958 - acc: 0.0397 - val_loss: 55.9595 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0944 - acc: 0.0398 - val_loss: 56.0152 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0938 - acc: 0.0362 - val_loss: 55.9705 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0933 - acc: 0.0427 - val_loss: 56.7441 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.0946 - acc: 0.0424 - val_loss: 55.3724 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0941 - acc: 0.0434 - val_loss: 55.6014 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.0933 - acc: 0.0417 - val_loss: 55.9719 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "25800/25800 [==============================] - 19s 724us/step - loss: 12.0921 - acc: 0.0420 - val_loss: 56.4376 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0948 - acc: 0.0457 - val_loss: 57.1647 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0948 - acc: 0.0419 - val_loss: 56.6351 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0948 - acc: 0.0424 - val_loss: 57.0567 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0943 - acc: 0.0440 - val_loss: 57.1860 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0941 - acc: 0.0433 - val_loss: 56.7925 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0926 - acc: 0.0460 - val_loss: 57.1123 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0944 - acc: 0.0444 - val_loss: 57.1760 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0938 - acc: 0.0430 - val_loss: 56.0977 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0941 - acc: 0.0424 - val_loss: 56.3845 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0934 - acc: 0.0392 - val_loss: 57.8283 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0933 - acc: 0.0419 - val_loss: 56.3465 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "25800/25800 [==============================] - 19s 725us/step - loss: 12.0950 - acc: 0.0440 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "25800/25800 [==============================] - 19s 732us/step - loss: 12.0947 - acc: 0.0467 - val_loss: 57.2641 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.0924 - acc: 0.0390 - val_loss: 57.6269 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "25800/25800 [==============================] - 19s 736us/step - loss: 12.0930 - acc: 0.0421 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "25800/25800 [==============================] - 19s 737us/step - loss: 12.0956 - acc: 0.0425 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0941 - acc: 0.0404 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      " 3584/25800 [===>..........................] - ETA: 14s - loss: 12.1202 - acc: 0.0421"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c7dcd17b81ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m hist = classifier.fit(x_train_ori, y_train_ori, batch_size=128, nb_epoch=100, verbose=1, \n\u001b[1;32m----> 4\u001b[1;33m                       validation_data=(x_test_ori, y_test_ori))\n\u001b[0m",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# randomly taking 10320 data samples\n",
    "classifier = build_model()\n",
    "hist = classifier.fit(x_train_ori, y_train_ori, batch_size=128, nb_epoch=100, verbose=1, \n",
    "                      validation_data=(x_test_ori, y_test_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_A():\n",
    "    filename = \"modelA_train.csv\"\n",
    "    csv_log = callbacks.CSVLogger(filename, separator=\",\", append=False)\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=1, mode=\"min\")\n",
    "    \n",
    "    filepath = \"Best-weights-my_model-{epoch:03d}-{loss:4f}-{acc:4f}.hdf5\"\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only= True, mode=\"min\")\n",
    "    \n",
    "    callbacks_list = [csv_log, early_stop, checkpoint]\n",
    "    \n",
    "    #build the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), input_shape=input_shape, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #second convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), activation=\"relu\", border_mode=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #third convolutional layer\n",
    "    model.add(Conv2D(64, (3,3), activation=\"relu\", border_mode = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #forth convolutional layer\n",
    "    model.add(Conv2D(64, (3,3), activation=\"relu\", border_mode = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #first FC layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "        \n",
    "    #second FC layer\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(24, activation=\"softmax\", kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25800 samples, validate on 5160 samples\n",
      "Epoch 1/40\n",
      "25800/25800 [==============================] - 23s 888us/step - loss: 12.2578 - acc: 0.0419 - val_loss: 58.3998 - val_acc: 0.0027\n",
      "Epoch 2/40\n",
      "25800/25800 [==============================] - 21s 816us/step - loss: 12.1596 - acc: 0.0400 - val_loss: 56.6712 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "25800/25800 [==============================] - 21s 817us/step - loss: 12.1405 - acc: 0.0452 - val_loss: 58.6842 - val_acc: 0.0097\n",
      "Epoch 4/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.1280 - acc: 0.0416 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 5/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.1260 - acc: 0.0433 - val_loss: 58.7311 - val_acc: 0.0000e+00\n",
      "Epoch 6/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.1156 - acc: 0.0462 - val_loss: 58.6811 - val_acc: 0.0638\n",
      "Epoch 7/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.1116 - acc: 0.0435 - val_loss: 58.6655 - val_acc: 0.0066\n",
      "Epoch 8/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.1079 - acc: 0.0430 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 9/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.1024 - acc: 0.0457 - val_loss: 58.7311 - val_acc: 0.0140\n",
      "Epoch 10/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.1001 - acc: 0.0403 - val_loss: 58.6686 - val_acc: 0.0054\n",
      "Epoch 11/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0955 - acc: 0.0443 - val_loss: 58.6686 - val_acc: 0.0054\n",
      "Epoch 12/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.0919 - acc: 0.0437 - val_loss: 58.6686 - val_acc: 0.0054\n",
      "Epoch 13/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.0902 - acc: 0.0395 - val_loss: 56.2003 - val_acc: 0.0227\n",
      "Epoch 14/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.0864 - acc: 0.0470 - val_loss: 58.0139 - val_acc: 0.0186\n",
      "Epoch 15/40\n",
      "25800/25800 [==============================] - 21s 822us/step - loss: 12.0842 - acc: 0.0409 - val_loss: 58.6905 - val_acc: 0.1395\n",
      "Epoch 16/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0846 - acc: 0.0373 - val_loss: 58.6905 - val_acc: 0.1395\n",
      "Epoch 17/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0812 - acc: 0.0471 - val_loss: 58.6717 - val_acc: 0.1213\n",
      "Epoch 18/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0807 - acc: 0.0447 - val_loss: 58.6717 - val_acc: 0.1213\n",
      "Epoch 19/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0799 - acc: 0.0383 - val_loss: 58.7019 - val_acc: 7.7519e-04\n",
      "Epoch 20/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0793 - acc: 0.0393 - val_loss: 57.7467 - val_acc: 7.7519e-04\n",
      "Epoch 21/40\n",
      "25800/25800 [==============================] - 21s 821us/step - loss: 12.0791 - acc: 0.0571 - val_loss: 58.6374 - val_acc: 1.9380e-04\n",
      "Epoch 22/40\n",
      "25800/25800 [==============================] - 21s 821us/step - loss: 12.0790 - acc: 0.0353 - val_loss: 58.6842 - val_acc: 0.0539\n",
      "Epoch 23/40\n",
      "25800/25800 [==============================] - 21s 822us/step - loss: 12.0790 - acc: 0.0372 - val_loss: 58.0037 - val_acc: 0.0539\n",
      "Epoch 24/40\n",
      "25800/25800 [==============================] - 21s 821us/step - loss: 12.0786 - acc: 0.0370 - val_loss: 58.6842 - val_acc: 0.0539\n",
      "Epoch 25/40\n",
      "25800/25800 [==============================] - 21s 820us/step - loss: 12.0786 - acc: 0.0414 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 26/40\n",
      "25800/25800 [==============================] - 21s 823us/step - loss: 12.0785 - acc: 0.0440 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 27/40\n",
      "25800/25800 [==============================] - 22s 836us/step - loss: 12.0787 - acc: 0.0340 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 28/40\n",
      "25800/25800 [==============================] - 22s 834us/step - loss: 12.0782 - acc: 0.0374 - val_loss: 57.9178 - val_acc: 0.0027\n",
      "Epoch 29/40\n",
      "25800/25800 [==============================] - 22s 837us/step - loss: 12.0785 - acc: 0.0721 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 30/40\n",
      "25800/25800 [==============================] - 21s 818us/step - loss: 12.0789 - acc: 0.0334 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 31/40\n",
      "25800/25800 [==============================] - 21s 819us/step - loss: 12.0786 - acc: 0.0385 - val_loss: 58.6655 - val_acc: 0.0066\n",
      "Epoch 32/40\n",
      "25800/25800 [==============================] - 21s 822us/step - loss: 12.0789 - acc: 0.0267 - val_loss: 58.7561 - val_acc: 0.0027\n",
      "Epoch 33/40\n",
      "25800/25800 [==============================] - 21s 824us/step - loss: 12.0788 - acc: 0.0310 - val_loss: 58.6905 - val_acc: 0.1395\n",
      "Epoch 34/40\n",
      "25800/25800 [==============================] - 22s 843us/step - loss: 12.0789 - acc: 0.0485 - val_loss: 58.6905 - val_acc: 0.1395\n",
      "Epoch 35/40\n",
      "25800/25800 [==============================] - 22s 844us/step - loss: 12.0788 - acc: 0.0349 - val_loss: 58.6842 - val_acc: 0.0539\n",
      "Epoch 36/40\n",
      "25800/25800 [==============================] - 22s 850us/step - loss: 12.0789 - acc: 0.0470 - val_loss: 58.7779 - val_acc: 0.0446\n",
      "Epoch 37/40\n",
      "25800/25800 [==============================] - 22s 855us/step - loss: 12.0788 - acc: 0.0381 - val_loss: 58.6842 - val_acc: 0.0539\n",
      "Epoch 38/40\n",
      "25800/25800 [==============================] - 22s 848us/step - loss: 12.0788 - acc: 0.0505 - val_loss: 58.6842 - val_acc: 0.0539\n",
      "Epoch 39/40\n",
      "25800/25800 [==============================] - 22s 845us/step - loss: 12.0790 - acc: 0.0507 - val_loss: 58.7030 - val_acc: 0.1581\n",
      "Epoch 40/40\n",
      "25800/25800 [==============================] - 22s 848us/step - loss: 12.0790 - acc: 0.0441 - val_loss: 58.7311 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# randomly taking 25800 data samples\n",
    "classifier_A = build_model_A()\n",
    "hist_A = classifier_A.fit(x_train_ori, y_train_ori, batch_size=64, nb_epoch=40, verbose=1, validation_data=(x_test_ori, y_test_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"weight-Test-CNN_A.hdf5\"\n",
    "classifier_A.save_weights(fname, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_B():\n",
    "    filename = \"model_train_B.csv\"\n",
    "    csv_log = callbacks.CSVLogger(filename, separator=\",\", append=False)\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=1, mode=\"min\")\n",
    "    \n",
    "    filepath = \"Best-weights-my_model-{epoch:03d}-{loss:4f}-{acc:4f}.hdf5\"\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only= True, mode=\"min\")\n",
    "    \n",
    "    callbacks_list = [csv_log, early_stop, checkpoint]\n",
    "    \n",
    "    #build the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), input_shape=input_shape, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #second convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), activation=\"relu\", border_mode=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #first FC layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(24, activation=\"softmax\", kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"SGD\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25800 samples, validate on 5160 samples\n",
      "Epoch 1/40\n",
      "25800/25800 [==============================] - 20s 761us/step - loss: 12.3171 - acc: 0.0397 - val_loss: 12.1256 - val_acc: 0.0097\n",
      "Epoch 2/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1525 - acc: 0.0407 - val_loss: 12.2068 - val_acc: 0.0446\n",
      "Epoch 3/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1167 - acc: 0.0428 - val_loss: 12.3817 - val_acc: 7.7519e-04\n",
      "Epoch 4/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1087 - acc: 0.0464 - val_loss: 12.1884 - val_acc: 0.0446\n",
      "Epoch 5/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1081 - acc: 0.0452 - val_loss: 12.1333 - val_acc: 0.0027\n",
      "Epoch 6/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1092 - acc: 0.0431 - val_loss: 13.3281 - val_acc: 0.0446\n",
      "Epoch 7/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1053 - acc: 0.0424 - val_loss: 12.9834 - val_acc: 0.0446\n",
      "Epoch 8/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1066 - acc: 0.0425 - val_loss: 12.7832 - val_acc: 0.0297\n",
      "Epoch 9/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1062 - acc: 0.0424 - val_loss: 12.6360 - val_acc: 0.0446\n",
      "Epoch 10/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1058 - acc: 0.0427 - val_loss: 12.4984 - val_acc: 0.0297\n",
      "Epoch 11/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1056 - acc: 0.0427 - val_loss: 13.3368 - val_acc: 0.0297\n",
      "Epoch 12/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.1049 - acc: 0.0423 - val_loss: 12.3184 - val_acc: 0.0446\n",
      "Epoch 13/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1051 - acc: 0.0447 - val_loss: 12.2099 - val_acc: 0.0446\n",
      "Epoch 14/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1050 - acc: 0.0415 - val_loss: 12.1190 - val_acc: 0.0097\n",
      "Epoch 15/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1061 - acc: 0.0429 - val_loss: 13.1522 - val_acc: 0.0446\n",
      "Epoch 16/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.1020 - acc: 0.0429 - val_loss: 12.1166 - val_acc: 0.1395\n",
      "Epoch 17/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.1039 - acc: 0.0438 - val_loss: 12.1315 - val_acc: 0.1043\n",
      "Epoch 18/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1059 - acc: 0.0438 - val_loss: 12.6294 - val_acc: 0.0446\n",
      "Epoch 19/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1017 - acc: 0.0433 - val_loss: 12.1041 - val_acc: 0.0066\n",
      "Epoch 20/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1041 - acc: 0.0407 - val_loss: 12.1558 - val_acc: 0.0027\n",
      "Epoch 21/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1036 - acc: 0.0436 - val_loss: 12.1320 - val_acc: 1.9380e-04\n",
      "Epoch 22/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1018 - acc: 0.0411 - val_loss: 12.3827 - val_acc: 0.0446\n",
      "Epoch 23/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1023 - acc: 0.0378 - val_loss: 12.2643 - val_acc: 0.0066\n",
      "Epoch 24/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1046 - acc: 0.0433 - val_loss: 12.1734 - val_acc: 0.0027\n",
      "Epoch 25/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1019 - acc: 0.0428 - val_loss: 12.1359 - val_acc: 0.0297\n",
      "Epoch 26/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1016 - acc: 0.0443 - val_loss: 12.1253 - val_acc: 7.7519e-04\n",
      "Epoch 27/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1020 - acc: 0.0440 - val_loss: 12.1023 - val_acc: 1.9380e-04\n",
      "Epoch 28/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1034 - acc: 0.0423 - val_loss: 12.1463 - val_acc: 0.0359\n",
      "Epoch 29/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1023 - acc: 0.0402 - val_loss: 12.1427 - val_acc: 0.0066\n",
      "Epoch 30/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1015 - acc: 0.0426 - val_loss: 12.2174 - val_acc: 9.6899e-04\n",
      "Epoch 31/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.1011 - acc: 0.0416 - val_loss: 12.8033 - val_acc: 0.0446\n",
      "Epoch 32/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1009 - acc: 0.0447 - val_loss: 12.6866 - val_acc: 0.0297\n",
      "Epoch 33/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1019 - acc: 0.0407 - val_loss: 12.3146 - val_acc: 0.1581\n",
      "Epoch 34/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1008 - acc: 0.0414 - val_loss: 12.4572 - val_acc: 0.0446\n",
      "Epoch 35/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1010 - acc: 0.0440 - val_loss: 13.0411 - val_acc: 0.0446\n",
      "Epoch 36/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1011 - acc: 0.0424 - val_loss: 12.3358 - val_acc: 0.0446\n",
      "Epoch 37/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.0999 - acc: 0.0443 - val_loss: 12.6643 - val_acc: 0.0186\n",
      "Epoch 38/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.0981 - acc: 0.0447 - val_loss: 12.8239 - val_acc: 0.0066\n",
      "Epoch 39/40\n",
      "25800/25800 [==============================] - 19s 728us/step - loss: 12.1018 - acc: 0.0444 - val_loss: 12.6703 - val_acc: 0.0446\n",
      "Epoch 40/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.1016 - acc: 0.0429 - val_loss: 13.5276 - val_acc: 0.0446\n"
     ]
    }
   ],
   "source": [
    "# randomly taking 25800 data samples\n",
    "classifier_B = build_model_B()\n",
    "hist_B = classifier_B.fit(x_train_ori, y_train_ori, batch_size=64, nb_epoch=40, verbose=1, \n",
    "                          validation_data=(x_test_ori, y_test_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"weight-Test-CNN_B.hdf5\"\n",
    "classifier_B.save_weights(fname, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_C():\n",
    "    filename = \"modelA_train.csv\"\n",
    "    csv_log = callbacks.CSVLogger(filename, separator=\",\", append=False)\n",
    "    \n",
    "    early_stop = callbacks.EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=3, verbose=1, mode=\"min\")\n",
    "    \n",
    "    filepath = \"Best-weights-my_model-{epoch:03d}-{loss:4f}-{acc:4f}.hdf5\"\n",
    "    checkpoint = callbacks.ModelCheckpoint(filepath, monitor=\"val_loss\", verbose=1, save_best_only= True, mode=\"min\")\n",
    "    \n",
    "    callbacks_list = [csv_log, early_stop, checkpoint]\n",
    "    \n",
    "    #build the model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), input_shape=input_shape, padding=\"same\", activation=\"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #second convolutional layer\n",
    "    model.add(Conv2D(32, (3,3), activation=\"relu\", border_mode=\"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #third convolutional layer\n",
    "    model.add(Conv2D(64, (3,3), activation=\"relu\", border_mode = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #forth convolutional layer\n",
    "    model.add(Conv2D(64, (3,3), activation=\"relu\", border_mode = \"same\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(2,2))\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #first FC layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "        \n",
    "    #second FC layer\n",
    "    model.add(Dense(256, activation=\"relu\", kernel_initializer=\"uniform\"))\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Dropout(0.2))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(Dense(24, activation=\"softmax\", kernel_initializer=\"uniform\"))\n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")`\n",
      "c:\\users\\zheng\\anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25800 samples, validate on 5160 samples\n",
      "Epoch 1/40\n",
      "25800/25800 [==============================] - 19s 747us/step - loss: 12.0989 - acc: 0.0436 - val_loss: 13.4296 - val_acc: 0.1581\n",
      "Epoch 2/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1005 - acc: 0.0436 - val_loss: 12.3314 - val_acc: 0.0446\n",
      "Epoch 3/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0998 - acc: 0.0437 - val_loss: 12.3964 - val_acc: 0.1581\n",
      "Epoch 4/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.1014 - acc: 0.0428 - val_loss: 12.6085 - val_acc: 0.0446\n",
      "Epoch 5/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.0999 - acc: 0.0416 - val_loss: 12.8277 - val_acc: 0.0446\n",
      "Epoch 6/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0995 - acc: 0.0453 - val_loss: 12.3218 - val_acc: 0.0446\n",
      "Epoch 7/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.1006 - acc: 0.0421 - val_loss: 12.3943 - val_acc: 0.1043\n",
      "Epoch 8/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.0995 - acc: 0.0448 - val_loss: 12.4964 - val_acc: 0.1043\n",
      "Epoch 9/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.0985 - acc: 0.0433 - val_loss: 12.5188 - val_acc: 0.0446\n",
      "Epoch 10/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0998 - acc: 0.0395 - val_loss: 13.3576 - val_acc: 0.0446\n",
      "Epoch 11/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.1005 - acc: 0.0422 - val_loss: 13.0745 - val_acc: 0.0446\n",
      "Epoch 12/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0996 - acc: 0.0386 - val_loss: 12.6765 - val_acc: 0.0446\n",
      "Epoch 13/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0988 - acc: 0.0409 - val_loss: 12.5695 - val_acc: 0.0446\n",
      "Epoch 14/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0995 - acc: 0.0410 - val_loss: 12.3605 - val_acc: 0.0446\n",
      "Epoch 15/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0997 - acc: 0.0444 - val_loss: 12.2011 - val_acc: 0.0446\n",
      "Epoch 16/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0988 - acc: 0.0420 - val_loss: 12.2832 - val_acc: 0.0446\n",
      "Epoch 17/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.0995 - acc: 0.0419 - val_loss: 12.3117 - val_acc: 0.0446\n",
      "Epoch 18/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.0998 - acc: 0.0415 - val_loss: 12.5004 - val_acc: 0.0446\n",
      "Epoch 19/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0972 - acc: 0.0417 - val_loss: 12.2832 - val_acc: 7.7519e-04\n",
      "Epoch 20/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.1004 - acc: 0.0450 - val_loss: 12.1984 - val_acc: 7.7519e-04\n",
      "Epoch 21/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0988 - acc: 0.0443 - val_loss: 12.1405 - val_acc: 0.0097\n",
      "Epoch 22/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0988 - acc: 0.0412 - val_loss: 12.1763 - val_acc: 0.1043\n",
      "Epoch 23/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0996 - acc: 0.0412 - val_loss: 12.1031 - val_acc: 0.1581\n",
      "Epoch 24/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0973 - acc: 0.0431 - val_loss: 12.3058 - val_acc: 0.1043\n",
      "Epoch 25/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.1004 - acc: 0.0466 - val_loss: 12.4061 - val_acc: 0.0446\n",
      "Epoch 26/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0979 - acc: 0.0430 - val_loss: 12.3070 - val_acc: 0.1043\n",
      "Epoch 27/40\n",
      "25800/25800 [==============================] - 19s 738us/step - loss: 12.0981 - acc: 0.0429 - val_loss: 12.1278 - val_acc: 0.1581\n",
      "Epoch 28/40\n",
      "25800/25800 [==============================] - 19s 745us/step - loss: 12.0980 - acc: 0.0423 - val_loss: 12.1113 - val_acc: 0.0638\n",
      "Epoch 29/40\n",
      "25800/25800 [==============================] - 19s 742us/step - loss: 12.0983 - acc: 0.0420 - val_loss: 12.4188 - val_acc: 0.0638\n",
      "Epoch 30/40\n",
      "25800/25800 [==============================] - 19s 740us/step - loss: 12.0965 - acc: 0.0411 - val_loss: 12.2438 - val_acc: 0.1043\n",
      "Epoch 31/40\n",
      "25800/25800 [==============================] - 19s 741us/step - loss: 12.0979 - acc: 0.0416 - val_loss: 12.3575 - val_acc: 0.1043\n",
      "Epoch 32/40\n",
      "25800/25800 [==============================] - 19s 735us/step - loss: 12.0969 - acc: 0.0446 - val_loss: 12.3480 - val_acc: 0.1043\n",
      "Epoch 33/40\n",
      "25800/25800 [==============================] - 19s 744us/step - loss: 12.0979 - acc: 0.0437 - val_loss: 12.3416 - val_acc: 0.0638\n",
      "Epoch 34/40\n",
      "25800/25800 [==============================] - 19s 729us/step - loss: 12.0964 - acc: 0.0425 - val_loss: 12.6553 - val_acc: 0.1043\n",
      "Epoch 35/40\n",
      "25800/25800 [==============================] - 19s 731us/step - loss: 12.0996 - acc: 0.0453 - val_loss: 12.3932 - val_acc: 0.0638\n",
      "Epoch 36/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0979 - acc: 0.0431 - val_loss: 12.2461 - val_acc: 0.0638\n",
      "Epoch 37/40\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0968 - acc: 0.0495 - val_loss: 12.2177 - val_acc: 0.0638\n",
      "Epoch 38/40\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0972 - acc: 0.0434 - val_loss: 12.2482 - val_acc: 0.0638\n",
      "Epoch 39/40\n",
      "25800/25800 [==============================] - 19s 726us/step - loss: 12.0999 - acc: 0.0461 - val_loss: 12.1531 - val_acc: 0.0097\n",
      "Epoch 40/40\n",
      "25800/25800 [==============================] - 19s 730us/step - loss: 12.0978 - acc: 0.0435 - val_loss: 12.6666 - val_acc: 0.0638\n"
     ]
    }
   ],
   "source": [
    "classifier_C = build_model_B()\n",
    "hist_C = classifier_B.fit(x_train_ori, y_train_ori, batch_size=64, nb_epoch=40, verbose=1, \n",
    "                          validation_data=(x_test_ori, y_test_ori))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"weight-Test-CNN_C.hdf5\"\n",
    "classifier_B.save_weights(fname, overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
