{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hui-Kang Tong admin, [2 Apr 2018 at 19:31:29]:\n",
    "ok we can now automatically generate midi files, convert midi files to wave files (with hkâ€™s mac)\n",
    "\n",
    "However to create training data, we need many data (audio samples) with the same target/label (note). So these are a few ways to vary it:\n",
    "- note velocity\n",
    "- note volume\n",
    "- noise\n",
    "- onset timing (one slightly later than the other)\n",
    "- soundfont (which mean instrument)\n",
    "\n",
    "So I will write a notebook which\n",
    "- leave a space for the function to create .mid file with note\n",
    "- use fluidsynth to convert this .mid file .wav\n",
    "- call this .mid file, identify onset with our onset function, and splice 4096 entries from it\n",
    "- leave a space for the training function\n",
    "- delete the .mid file and .wav file\n",
    "- repeat\n",
    "\n",
    "What needs to be considered/written\n",
    "what kind of model are we using, how do we train such a model, what sort of instructions does the .mid files have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from midiutil.MidiFile import MIDIFile\n",
    "from itertools import combinations\n",
    "import os\n",
    "import subprocess\n",
    "from time import sleep\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for onset detection\n",
    "\n",
    "def rcoeff_(snippet):\n",
    "    return np.corrcoef(snippet, np.arange(len(snippet)))[0, 1]\n",
    "\n",
    "rcoeff = np.vectorize(rcoeff_, signature='(n)->()')\n",
    "\n",
    "def divide_chunks(signal, intervals, snippet_size):\n",
    "# yield successive n-sized chunks from l.\n",
    "    for i in range(0, len(signal) - snippet_size, intervals):\n",
    "        # looping till the end of the array\n",
    "        yield signal[i:i + snippet_size]\n",
    "        \n",
    "def max_to_one(arr):\n",
    "    '''Scale the maximum of an array to one'''\n",
    "    return np.divide(arr, np.max(np.absolute(arr)))\n",
    "\n",
    "def detect_onset_given_entire_signal(signal, plotting=True):\n",
    "    '''\n",
    "    Onset detection function. Could be replaced with a better one.\n",
    "    Returns two signals, \n",
    "    - a short one (fixed at length 4096) for a standard note evaluation algorithm, \n",
    "    - a long one (usually 3*4096) for making spectrograms and applying machine learning algorithms like CNN.\n",
    "    (Why not standardise them, return the longer one instead?)\n",
    "    Onset detection is carried out every 32 points so we do not have to calculate the r-value of 4096 points at every point.\n",
    "    '''\n",
    "#     print(len(signal))\n",
    "    signal_cs = np.cumsum(np.absolute(signal))\n",
    "    signal_cs = np.add(signal_cs, np.random.randn(len(signal_cs)))\n",
    "#     print(len(signal_cs))\n",
    "    signal_chunk_sum = signal_cs[4096:] - signal_cs[:-4096]\n",
    "    snippets = np.array(list(divide_chunks(signal_chunk_sum, 32, 4096)))\n",
    "    signal_rcoeff = rcoeff(snippets)\n",
    "\n",
    "#     print(\"loc\")\n",
    "#     print(signal_rcoeff)\n",
    "#     print(np.where(signal_rcoeff>0.8)[0][0])\n",
    "    location = np.where(signal_rcoeff>0.8)[0][0]\n",
    "    start_pt, end_pt = location*32+7168, location*32+7168+4096\n",
    "    map_start_pt = location*32+7168-3*4096\n",
    "    if map_start_pt < 0:\n",
    "        map_start_pt = 0\n",
    "    \n",
    "    if plotting:\n",
    "        plt.plot(np.arange(4096, len(signal)), max_to_one(signal_chunk_sum))\n",
    "        plt.plot(np.arange(4096*2, len(signal), 32), signal_rcoeff)\n",
    "        plt.axvline(x=start_pt,color=\"red\")\n",
    "        plt.axvline(x=end_pt,color=\"red\")\n",
    "        plt.show()\n",
    "        \n",
    "    return signal[start_pt:end_pt], signal[map_start_pt:end_pt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cqt_function(signal_to_ayse):\n",
    "    '''\n",
    "    Compute the cqt response over a set of notes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    signal_to_ayse : input array, real\n",
    "                     4096 entries long\n",
    "\n",
    "    Output\n",
    "    ----------\n",
    "    MIDI numbers\n",
    "    60 is middle C, which is C4\n",
    "    \n",
    "    Todo\n",
    "    ----\n",
    "    We should not be generating the kernels every time.\n",
    "    Actually we could simply multiply with the FFT of the signal.\n",
    "    So:\n",
    "    Make it customisable to a random starting note.\n",
    "    Outsource the precomputation to a function instead - do something like load kernels.\n",
    "    Do both of these at the same time.\n",
    "    (but anyway we just want an accurate demo, computation time doesn't seem to be a problem here)\n",
    "    '''\n",
    "\n",
    "    length = len(signal_to_ayse)\n",
    "#     print(length)\n",
    "\n",
    "    # fast fourier transform\n",
    "    freq_domain = np.fft.fft(signal_to_ayse)\n",
    "    \n",
    "    # defining the 36 notes bins\n",
    "    bins = 40\n",
    "    freq_ref_notes = [261.625565 * (2. ** (n / 36. - 5. / 72.)) for n in range(bins)]\n",
    "\n",
    "    # defining the time kernel\n",
    "    # different note have different \"kernels\"\n",
    "    bell_curves = []\n",
    "    for note in range(len(freq_ref_notes)):\n",
    "        # I don't think this is defined properly?\n",
    "        bell_curve = np.exp(-((np.arange(-1., 1., 2. / length)) * (2. ** (note / 36.))) ** 2.)\n",
    "        bell_curves.append(bell_curve)\n",
    "\n",
    "    # multiplying the waveform with the window\n",
    "    kernels = []\n",
    "    for note in range(bins):\n",
    "        # generate cosine/sine wave\n",
    "        wave = np.exp((np.arange(length) - length / 2.) * -1.j * 2. * np.pi * freq_ref_notes[note] / 44100.)\n",
    "        # multiplying a window over it\n",
    "        kernels.append(np.multiply(wave, bell_curves[note]))\n",
    "\n",
    "    # taking fourier transform for the frequency kernel\n",
    "    fft_kernels = []\n",
    "    for note in range(bins):\n",
    "        fft_kernels.append(np.fft.fft(kernels[note]))\n",
    "    # all of the above should be run only once\n",
    "    # but the maximum complexity is only the FFT, it is still not a problem\n",
    "    # the focus is an MVP anyway\n",
    "    # we prioritse accuracy here though\n",
    "    # creating arrays to populate for each one-third-semitone\n",
    "    cqt_resp_specs = []\n",
    "    cqt_resp = []\n",
    "\n",
    "    # populating the arrays\n",
    "    for note in range(bins):\n",
    "        cqt_resp_spec = []\n",
    "        for entry in range(length):\n",
    "            cqt_resp_spec.append(fft_kernels[note][entry] * freq_domain[entry])\n",
    "        cqt_resp_specs.append(cqt_resp_spec)\n",
    "        cqt_resp.append(sum([abs(x) for x in cqt_resp_spec]))\n",
    "\n",
    "    # finding peaks in the cqt response\n",
    "    notesrum = cqt_resp  # remove redundant variable please\n",
    "\n",
    "    #     plt.figure(figsize=(16,2))\n",
    "    #     plt.plot(np.linspace(0, 70*44100/4096, num=70, endpoint=False),\n",
    "    #              np.absolute(freq_domain[:70])/np.max(np.absolute(freq_domain[:70])))\n",
    "    #     plt.plot(np.geomspace(261.625565*2**(-3/36), 261.625565*2**(37/36), num=40, endpoint=False),\n",
    "    #              np.absolute(cqt_resp)/np.max(np.absolute(cqt_resp)))\n",
    "    #     plt.show()\n",
    "\n",
    "    notesrum_peak_only = [0.0] * len(notesrum)\n",
    "    notesrum_sum = sum(notesrum)\n",
    "\n",
    "    for index in range(bins - 1)[1:]:\n",
    "        if notesrum[index - 1] < notesrum[index] and notesrum[index + 1] < notesrum[index]:\n",
    "            notesrum_peak_only[index] = notesrum[index]\n",
    "\n",
    "        # known_octave = notesrum_peak_only[12:12+36] # don't know what is this for\n",
    "    known_octave = notesrum_peak_only[2:-2]\n",
    "    # print(np.round(known_octave,5)/notesrum_sum)\n",
    "\n",
    "    notesrum_peak_only_sum = sum(notesrum_peak_only)\n",
    "\n",
    "    for x in range(36):\n",
    "        # if known_octave[x]/notesrum_sum < 0.1:\n",
    "        if known_octave[x] / notesrum_peak_only_sum < 0.2:\n",
    "            known_octave[x] = 0\n",
    "\n",
    "    known_octave_notes = []\n",
    "    for notes in range(36 // 3):\n",
    "        known_octave_notes.append(known_octave[3 * notes]\n",
    "                                  + known_octave[3 * notes + 1]\n",
    "                                  + known_octave[3 * notes + 2])\n",
    "\n",
    "    # notestrum_sum = sum(notesrum)  # alternate demoninator to calc threshold\n",
    "    # print(np.round(known_octave_notes,5)/notesrum_peak_only_sum)\n",
    "    # print(\"check\")\n",
    "\n",
    "    notesrum_peak_only_sum = sum(notesrum_peak_only)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    for x in range(12):\n",
    "        if known_octave_notes[x] / notesrum_peak_only_sum > 0.1:\n",
    "            output.append(x + 60)\n",
    "\n",
    "    #     plt.figure(figsize=(16,2))\n",
    "    #     plt.plot(notesrum_peak_only)\n",
    "    #     plt.plot(notesrum)\n",
    "    #     plt.axhline(y=0.1*notesrum_peak_only_sum, color='r', linestyle='-')\n",
    "    #     plt.show()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_midi_file(com,midi_instructions):\n",
    "    # generate and save midifile\n",
    "    mf = MIDIFile(len(com))\n",
    "    \n",
    "    track, channel, time, duration, volume = midi_instructions\n",
    "    \n",
    "    for i in range(len(com)):\n",
    "        mf.addNote(track, channel, com[i], time, duration, volume)\n",
    "\n",
    "    code = []\n",
    "    for num in com:\n",
    "        code.append(num)\n",
    "    while len(code) < 4:\n",
    "        code.append(\"x\")\n",
    "\n",
    "    filename = \"C{}_{}_{}_{}_{}\".format(4, code[0], code[1], code[2], code[3])\n",
    "    # first argument not necessary - convention to be updated\n",
    "    print(filename)\n",
    "    with open(\"midifile_sch/{}.mid\".format(filename), \"wb\") as outf:\n",
    "        mf.writeFile(outf)\n",
    "        \n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_midi_to_signal(filename):\n",
    "    '''\n",
    "    Given filename, create soundfile.\n",
    "    It uses fluidsynth to convert the midifile from the directory into a soundfile in another directory.\n",
    "    Installation of fluidsynth is necessary to run this.\n",
    "    https://github.com/FluidSynth/fluidsynth/wiki/BuildingWithCMake\n",
    "    returns mono signal - could we use stereo information for evaluation someday?\n",
    "    '''\n",
    "    soundfont_dir = \"~/soundfonts/GeneralUser\\ GS\\ v1.471.sf2\"\n",
    "    subprocess.run(\"fluidsynth -F soundfile_sch/{}.wav {} midifile_sch/{}.mid\"\n",
    "                   .format(filename,soundfont_dir,filename),shell=True)\n",
    "    sleep(1)\n",
    "    audio,sr = sf.read(\"soundfile_sch/{}.wav\".format(filename))\n",
    "    if type(audio[0]) != float or type(audio[0]) != int: \n",
    "        # if stereo (expected)\n",
    "        signal = audio[:,0]  \n",
    "    else:    \n",
    "        # if mono (but I have yet to try this out)\n",
    "        signal = audio[:]\n",
    "    assert (signal[0] != float or signal[0] != int)\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "# Functions for note evaluation\n",
    "\n",
    "def plot_spectrum(signal_to_ayse):\n",
    "    freq_domain = np.fft.fft(signal_to_ayse)\n",
    "    plt.figure(figsize=(12,2))\n",
    "    plt.plot(np.linspace(0, 250*44100/4096., 250, endpoint=True), np.absolute(freq_domain[:250]))\n",
    "    plt.xlabel(\"frequency (Hz)\")\n",
    "    plt.title(\"Spectrum of signal analysed\")\n",
    "    plt.axvline(x = 261.625565, color=\"red\")\n",
    "    plt.axvline(x = 261.625565*2., color=\"red\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrograms(signal_to_ayse, signal_to_map):\n",
    "    '''\n",
    "    Plots\n",
    "    - a spectrum from signal_to_ayse \n",
    "    - three spectrograms from signal_to_map\n",
    "    You can customise them.\n",
    "    '''\n",
    "    plot_spectrum(signal_to_ayse)\n",
    "    \n",
    "    plt.figure(figsize=(12,9))\n",
    "    \n",
    "    # https://librosa.github.io/librosa/generated/librosa.display.specshow.html\n",
    "    plt.subplot(131)\n",
    "    D = librosa.stft(signal_to_map)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(librosa.magphase(D)[0], ref=np.max),\n",
    "                                                     y_axis='linear', x_axis='time')\n",
    "    plt.title('Power spectrogram (linear)')\n",
    "    \n",
    "    plt.subplot(132)\n",
    "    D = librosa.stft(signal_to_map)\n",
    "    librosa.display.specshow(librosa.amplitude_to_db(librosa.magphase(D)[0], ref=np.max),\n",
    "                                                     y_axis='log', x_axis='time')\n",
    "    plt.title('Power spectrogram (log)')\n",
    "    \n",
    "    # https://librosa.github.io/librosa/generated/librosa.core.cqt.html\n",
    "    plt.subplot(133)\n",
    "    CQT = librosa.amplitude_to_db(np.absolute(librosa.cqt(signal_to_map, sr=44100)), \n",
    "                                  ref=np.max)\n",
    "    librosa.display.specshow(CQT, y_axis='cqt_note')\n",
    "    plt.title('Constant-Q power spectrogram (note)')\n",
    "    \n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function_accuracy_single(note_detection_function_to_test,\n",
    "                                  com, midi_instructions,\n",
    "                                  plotting=True, deleting=True):\n",
    "    '''\n",
    "    Make plotting False if you do not want see the plots.\n",
    "    Make deleting False if you do not want to delete the file after testing\n",
    "    '''\n",
    "    \n",
    "    # generate midi file\n",
    "    filename = generate_midi_file(com,midi_instructions)\n",
    "    \n",
    "    # convert midi file to signal\n",
    "    signal = convert_midi_to_signal(filename)\n",
    "    \n",
    "    if plotting:\n",
    "        sd.play(signal, 44100)\n",
    "        sleep(1)\n",
    "        plt.figure(figsize=(12,2))\n",
    "        plt.plot(signal)\n",
    "        # plt.show()\n",
    "    \n",
    "    # onset detection\n",
    "    signal_to_ayse, signal_to_map = detect_onset_given_entire_signal(signal, plotting)\n",
    "    \n",
    "\n",
    "    if plotting:\n",
    "        plt.figure(figsize=(12,2))\n",
    "        plt.plot(signal_to_map)\n",
    "        plt.title(\"Signal analysed\")\n",
    "        plt.axvline(x=len(signal_to_map)-4096, color=\"red\")\n",
    "        plt.axvline(x=len(signal_to_map), color=\"red\")\n",
    "        plt.show()\n",
    "    \n",
    "        plot_spectrograms(signal_to_ayse, signal_to_map)\n",
    "    \n",
    "    # note detection\n",
    "    # given a 4096 length snippet find out the what are notes\n",
    "    # probably use this to evaluate the accuracy\n",
    "    # make this train also\n",
    "\n",
    "    result = note_detection_function_to_test(signal_to_ayse)\n",
    "    print(\"--results--\")\n",
    "    print(com)\n",
    "    print(result)\n",
    "    print(\"===========\")\n",
    "    \n",
    "    sleep(1)\n",
    "    if deleting:\n",
    "        # remove midifile\n",
    "        subprocess.run(\"rm midifile_sch/{}.wav\".format(filename),shell=True) \n",
    "        # remove soundfile\n",
    "        subprocess.run(\"rm soundfile_sch/{}.wav\".format(filename),shell=True)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test_function_accuracy(note_detection_function_to_test, plotting = True):\n",
    "    \n",
    "    scales = range(5,6)  # C4 (middle C) to C5\n",
    "    no_of_notes = range(2, 5)  # 2 notes to 4 notes\n",
    "\n",
    "    channel = 0\n",
    "    time = 0.5\n",
    "    duration = 2\n",
    "    tempo = 100\n",
    "    volume = 100\n",
    "    track = 1\n",
    "    \n",
    "    # can loop in other ways or random\n",
    "    comb_list = []\n",
    "    for scale in scales:\n",
    "        for no_ in no_of_notes:\n",
    "\n",
    "            pitch = range(12*(scale), 12*(scale+1))\n",
    "            comb = [list(x) for x in combinations(pitch, no_)]\n",
    "            comb_list += comb\n",
    "            \n",
    "    midi_instructions = track, channel, time, duration, volume \n",
    "\n",
    "    stats = []\n",
    "    for com in np.random.permutation(comb_list):\n",
    "        result = test_function_accuracy_single(note_detection_function_to_test,\n",
    "                                               com, midi_instructions,\n",
    "                                               plotting)\n",
    "        notes_present = len(com)\n",
    "        notes_detected = len(result)\n",
    "        present_and_detected = sum(x in com for x in result)\n",
    "        not_present_but_detected = sum(x not in com for x in result)\n",
    "        present_but_not_detected = sum(x not in result for x in com)\n",
    "        stats.append([notes_present,\n",
    "                     notes_detected,\n",
    "                     present_and_detected,\n",
    "                     not_present_but_detected,\n",
    "                     present_but_not_detected])\n",
    "        print(stats[-1])\n",
    "        # print some cumulative statistics here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4_63_66_70_x\n",
      "--results--\n",
      "[63, 66, 70]\n",
      "[63, 66, 70]\n",
      "===========\n",
      "[3, 3, 3, 0, 0]\n",
      "C4_64_65_66_71\n",
      "--results--\n",
      "[64, 65, 66, 71]\n",
      "[64, 65]\n",
      "===========\n",
      "[4, 2, 2, 0, 2]\n",
      "C4_63_64_70_x\n",
      "--results--\n",
      "[63, 64, 70]\n",
      "[63, 70]\n",
      "===========\n",
      "[3, 2, 2, 0, 1]\n",
      "C4_61_67_70_x\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4d72138b9c1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtest_function_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcqt_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-24f97ee5735f>\u001b[0m in \u001b[0;36mtest_function_accuracy\u001b[0;34m(note_detection_function_to_test, plotting)\u001b[0m\n\u001b[1;32m     26\u001b[0m         result = test_function_accuracy_single(note_detection_function_to_test,\n\u001b[1;32m     27\u001b[0m                                                \u001b[0mcom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmidi_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                                                plotting)\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mnotes_present\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mnotes_detected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-52e5185ae8da>\u001b[0m in \u001b[0;36mtest_function_accuracy_single\u001b[0;34m(note_detection_function_to_test, com, midi_instructions, plotting, deleting)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# convert midi file to signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_midi_to_signal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mplotting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-580ccd4729ad>\u001b[0m in \u001b[0;36mconvert_midi_to_signal\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m     subprocess.run(\"fluidsynth -F soundfile_sch/{}.wav {} midifile_sch/{}.mid\"\n\u001b[1;32m     11\u001b[0m                    .format(filename,soundfont_dir,filename),shell=True)\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"soundfile_sch/{}.wav\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_function_accuracy(cqt_function, plotting=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C4_61_65_70_71\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    test_function_accuracy(cqt_function, plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mir]",
   "language": "python",
   "name": "conda-env-mir-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
